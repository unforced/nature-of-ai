{
  "id": "neural-networks",
  "slug": "neural-networks",
  "title": "10. Neural Networks",
  "type": "chapter",
  "content": "\nChapter 10. Neural Networks\n\n  \n    The human brain has 100 billion neurons,\n    each neuron connected to 10 thousand\n    other neurons. Sitting on your shoulders\n    is the most complicated object\n    in the known universe.\n    \n      —Michio Kaku\n    \n  \n\n\n  \n    \n    \n  \n  Khipu on display at the Machu Picchu Museum, Cusco, Peru (photo by Pi3.124)\n  The khipu (or quipu) is an ancient Incan device used for recordkeeping and communication. It comprised a complex system of knotted cords to encode and transmit information. Each colored string and knot type and pattern represented specific data, such as census records or calendrical information. Interpreters, known as quipucamayocs, acted as a kind of accountant and decoded the stringed narrative into understandable information.\n\nI began with inanimate objects living in a world of forces, and I gave them desires, autonomy, and the ability to take action according to a system of rules. Next, I allowed those objects, now called creatures, to live in a population and evolve over time. Now I’d like to ask, What is each creature’s decision-making process? How can it adjust its choices by learning over time? Can a computational entity process its environment and generate a decision?\nTo answer these questions, I’ll once again look to nature for inspiration—specifically, the human brain. A brain can be described as a biological neural network, an interconnected web of neurons transmitting elaborate patterns of electrical signals. Within each neuron, dendrites receive input signals, and based on those inputs, the neuron fires an output signal via an axon (see Figure 10.1). Or something like that. How the human brain actually works is an elaborate and complex mystery, one that I’m certainly not going to attempt to unravel in rigorous detail in this chapter.\n\n  \n  Figure 10.1: A neuron with dendrites and an axon connected to another neuron\n\nFortunately, as you’ve seen throughout this book, developing engaging animated systems with code doesn’t require scientific rigor or accuracy. Designing a smart rocket isn’t rocket science, and neither is designing an artificial neural network brain science. It’s enough to simply be inspired by the idea of brain function.\nIn this chapter, I’ll begin with a conceptual overview of the properties and features of neural networks and build the simplest possible example of one, a network that consists of a single neuron. I’ll then introduce you to more complex neural networks by using the ml5.js library. This will serve as a foundation for Chapter 11, the grand finale of this book, where I’ll combine GAs with neural networks for physics simulation.\nIntroducing Artificial Neural Networks\nComputer scientists have long been inspired by the human brain. In 1943, Warren S. McCulloch, a neuroscientist, and Walter Pitts, a logician, developed the first conceptual model of an artificial neural network. In their paper “A Logical Calculus of the Ideas Immanent in Nervous Activity,” they describe a neuron as a single computational cell living in a network of cells that receives inputs, processes those inputs, and generates an output.\nTheir work, and the work of many scientists and researchers who followed, wasn’t meant to accurately describe how the biological brain works. Rather, an artificial neural network (hereafter referred to as just a neural network) was intended as a computational model based on the brain, designed to solve certain kinds of problems that were traditionally difficult for computers.\nSome problems are incredibly simple for a computer to solve but difficult for humans like you and me. Finding the square root of 964,324 is an example. A quick line of code produces the value 982, a number my computer can compute in less than a millisecond, but if you asked me to calculate that number myself, you’d be in for quite a wait. On the other hand, certain problems are incredibly simple for you or me to solve, but not so easy for a computer. Show any toddler a picture of a kitten or puppy, and they’ll quickly be able to tell you which one is which. Listen to a conversation in a noisy café and focus on just one person’s voice, and you can effortlessly comprehend their words. But need a machine to perform one of these tasks? Scientists have spent entire careers researching and implementing complex solutions, and neural networks are one of them.\nHere are some of the easy-for-a-human, difficult-for-a-machine applications of neural networks in software today:\n\n  Pattern recognition: Neural networks are well suited to problems when the aim is to detect, interpret, and classify features or patterns within a dataset. This includes everything from identifying objects (like faces) in images, to optical character recognition, to more complex tasks like gesture recognition.\n  Time-series prediction and anomaly detection: Neural networks are utilized both in forecasting, such as predicting stock market trends or weather patterns, and in recognizing anomalies, which can be applied to areas like cyberattack detection and fraud prevention.\n  Control and adaptive decision-making systems: These applications range from autonomous vehicles like self-driving cars and drones to adaptive decision-making used in game playing, pricing models, and recommendation systems on media platforms.\n  Signal processing and soft sensors: Neural networks play a crucial role in devices like cochlear implants and hearing aids by filtering noise and amplifying essential sounds. They’re also involved in soft sensors, software systems that process data from multiple sources to give a comprehensive analysis of the environment.\n  Natural language processing (NLP): One of the biggest developments in recent years has been the use of neural networks for processing and understanding human language. They’re used in various tasks including machine translation, sentiment analysis, and text summarization, and are the underlying technology behind many digital assistants and chatbots.\n  Generative models: The rise of novel neural network architectures has made it possible to generate new content. These systems can synthesize images, enhance image resolution, transfer style between images, and even generate music and video.\n\nCovering the full gamut of applications for neural networks would merit an entire book (or series of books), and by the time that book was printed, it would probably be out of date. Hopefully, this list gives you an overall sense of the features and possibilities.\nHow Neural Networks Work\nIn some ways, neural networks are quite different from other computer programs. The computational systems I’ve been writing so far in this book are procedural: a program starts at the first line of code, executes it, and goes on to the next, following instructions in a linear fashion. By contrast, a true neural network doesn’t follow a linear path. Instead, information is processed collectively, in parallel, throughout a network of nodes, with each node representing a neuron. In this sense, a neural network is considered a connectionist system.\nIn other ways, neural networks aren’t so different from some of the programs you’ve seen. A neural network exhibits all the hallmarks of a complex system, much like a cellular automaton or a flock of boids. Remember how each individual boid was simple to understand, yet by following only three rules—separation, alignment, cohesion—it contributed to complex behaviors? Each individual element in a neural network is equally simple to understand. It reads an input (a number), processes it, and generates an output (another number). That’s all there is to it, and yet a network of many neurons can exhibit incredibly rich and intelligent behaviors, echoing the complex dynamics seen in a flock of boids.\n\n  \n    \n    Figure 10.2: A neural network is a system of neurons and connections.\n  \n\nIn fact, a neural network isn’t just a complex system, but a complex adaptive system, meaning it can change its internal structure based on the information flowing through it. In other words, it has the ability to learn. Typically, this is achieved by adjusting weights. In Figure 10.2, each arrow represents a connection between two neurons and indicates the pathway for the flow of information. Each connection has a weight, a number that controls the signal between the two neurons. If the network generates a good output (which I’ll define later), there’s no need to adjust the weights. However, if the network generates a poor output—an error, so to speak—then the system adapts, altering the weights with the hope of improving subsequent results.\nNeural networks may use a variety of strategies for learning, and I’ll focus on one of them in this chapter:\n\n  Supervised learning: Essentially, this strategy involves a teacher that’s smarter than the network itself. Take the case of facial recognition. The teacher shows the network a bunch of faces, and the teacher already knows the name associated with each face. The network makes its guesses; then the teacher provides the network with the actual names. The network can compare its answers to the known correct ones and make adjustments according to its errors. The neural networks in this chapter follow this model.\n  Unsupervised learning: This technique is required when you don’t have an example dataset with known answers. Instead, the network works on its own to uncover hidden patterns in the data. An application of this is clustering: a set of elements is divided into groups according to an unknown pattern. I won’t be showing any instances of unsupervised learning, as the strategy is less relevant to the book’s examples.\n  Reinforcement learning: This strategy is built on observation: a learning agent makes decisions and looks to its environment for the results. It’s rewarded for good decisions and penalized for bad decisions, such that it learns to make better decisions over time. I’ll discuss this strategy in more detail in Chapter 11.\n\nThe ability of a neural network to learn, to make adjustments to its structure over time, is what makes it so useful in the field of machine learning. This term can be traced back to the 1959 paper “Some Studies in Machine Learning Using the Game of Checkers,” in which computer scientist Arthur Lee Samuel outlines a “self-learning” program for playing checkers. The concept of an algorithm enabling a computer to learn without explicit programming is the foundation of machine learning.\nThink about what you’ve been doing throughout this book: coding! In traditional programming, a computer program takes inputs and, based on the rules you’ve provided, produces outputs. Machine learning, however, turns this approach upside down. Instead of you writing the rules, the system is given example inputs and outputs, and generates the rules itself! Many algorithms can be used to implement machine learning, and a neural network is just one of them.\nMachine learning is part of the broad, sweeping field of artificial intelligence (AI), although the terms are sometimes used interchangeably. In their thoughtful and friendly primer A People’s Guide to AI, Mimi Onuoha and Diana Nucera (aka Mother Cyborg) define AI as “the theory and development of computer systems able to perform tasks that normally require human intelligence.” Machine learning algorithms are one approach to these tasks, but not all AI systems feature a self-learning component.\nMachine Learning Libraries\nToday, leveraging machine learning in creative coding and interactive media isn’t only feasible but increasingly common, thanks to third-party libraries that handle a lot of the neural network implementation details under the hood. While the vast majority of machine learning development and research is done in Python, the world of web development has seen the emergence of powerful JavaScript-based tools. Two libraries of note are TensorFlow.js and ml5.js.\nTensorFlow.js is an open source library that lets you define, train, and run neural networks directly in the browser using JavaScript, without the need to install or configure complex environments. It’s part of the TensorFlow ecosystem, which is maintained and developed by Google. TensorFlow.js is a powerful tool, but its low-level operations and highly technical API can be intimidating to beginners. Enter ml5.js, a library built on top of TensorFlow.js and designed specifically for use with p5.js. Its goal is to be beginner friendly and make machine learning approachable for a broad audience of artists, creative coders, and students. I’ll demonstrate how to use ml5.js in “Machine Learning with ml5.js”.\nA benefit of libraries like TensorFlow.js and ml5.js is that you can use them to run pretrained models. A machine learning model is a specific setup of neurons and connections, and a pretrained model is one that has already been prepared for a particular task. For example, popular pretrained models are used for classifying images, identifying body poses, recognizing facial landmarks or hand positions, and even analyzing the sentiment expressed in a text. You can use such a model as is or treat it as a starting point for additional learning (commonly referred to as transfer learning).\nBefore I get to exploring the ml5.js library, however, I’d like to try my hand at building the simplest of all neural networks from scratch, using only p5.js, to illustrate how the concepts of neural networks and machine learning are implemented in code.\nThe Perceptron\n\n\nA perceptron is the simplest neural network possible: a computational model of a single neuron. Invented in 1957 by Frank Rosenblatt at the Cornell Aeronautical Laboratory, a perceptron consists of one or more inputs, a processor, and a single output, as shown in Figure 10.3.\n\n  \n  Figure 10.3: A simple perceptron with two inputs and one output\n\nA perceptron follows the feed-forward model: data passes (feeds) through the network in one direction. The inputs are sent into the neuron, are processed, and result in an output. This means the one-neuron network diagrammed in Figure 10.3 reads from left to right (forward): inputs come in, and output goes out.\nSay I have a perceptron with two inputs, the values 12 and 4. In machine learning, it’s customary to denote each input with an x, so I’ll call these inputs x_0 and x_1:\n\n  \n    \n      Input\n      Value\n    \n  \n  \n    \n      x_0\n      12\n    \n    \n      x_1\n      4\n    \n  \n\nPerceptron Steps\nTo get from these inputs to an output, the perceptron follows a series of steps.\nStep 1: Weight the Inputs\nEach input sent into the neuron must first be weighted, meaning it’s multiplied by a value, often a number from –1 to +1. When creating a perceptron, the inputs are typically assigned random weights. I’ll call my weights w_0 and w_1:\n\n  \n    \n      Weight\n      Value\n    \n  \n  \n    \n      w_0\n      0.5\n    \n    \n      w_1\n      –1\n    \n  \n\n\n  Each input needs to be multiplied by its corresponding weight:\n  \n    \n      \n        Input\n        Weight\n        Input \\boldsymbol{\\times} Weight\n      \n    \n    \n      \n        12\n        0.5\n        6\n      \n      \n        4\n        –1\n        –4\n      \n    \n  \n\nStep 2: Sum the Inputs\nThe weighted inputs are then added together:\n6 + -4 = 2\nStep 3: Generate the Output\nThe output of a perceptron is produced by passing the sum through an activation function that reduces the output to one of two possible values. Think of this binary output as an LED that’s only off or on, or as a neuron in an actual brain that either fires or doesn’t fire. The activation function determines whether the perceptron should “fire.”\nActivation functions can get a little bit hairy. If you start reading about them in an AI textbook, you may soon find yourself reaching in turn for a calculus textbook. However, your new friend the simple perceptron provides an easier option that still demonstrates the concept. I’ll make the activation function the sign of the sum. If the sum is a positive number, the output is 1; if it’s negative, the output is –1:\n\\text{sign}(2) = +1\nPutting It All Together\nPutting the preceding three parts together, here are the steps of the perceptron algorithm:\n\n  For every input, multiply that input by its weight.\n  Sum all the weighted inputs.\n  Compute the output of the perceptron by passing that sum through an activation function (the sign of the sum).\n\nI can start writing this algorithm in code by using two arrays of values, one for the inputs and one for the weights:\nlet inputs = [12, 4];\nlet weights = [0.5, -1];\nThe “for every input” in step 1 implies a loop that multiplies each input by its corresponding weight. To obtain the sum, the results can be added up in that same loop:\n// Steps 1 and 2: Add up all the weighted inputs.\nlet sum = 0;\nfor (let i = 0; i < inputs.length; i++) {\n  sum += inputs[i] * weights[i];\n}\nWith the sum, I can then compute the output:\n// Step 3: Pass the sum through an activation function.\nlet output = activate(sum);\n// The activation function\nfunction activate(sum) {\n  //{!5} Return a 1 if positive, –1 if negative.\n  if (sum > 0) {\n    return 1;\n  } else {\n    return -1;\n  }\n}\nYou might be wondering how I’m handling the value of 0 in the activation function. Is 0 positive or negative? The deep philosophical implications of this question aside, I’m choosing here to arbitrarily return a –1 for 0, but I could easily change the > to >= to go the other way. Depending on the application, this decision could be significant, but for demonstration purposes here, I can just pick one.\nNow that I’ve explained the computational process of a perceptron, let’s look at an example of one in action.\nSimple Pattern Recognition Using a Perceptron\nI’ve mentioned that neural networks are commonly used for pattern recognition. The scenarios outlined earlier require more complex networks, but even a simple perceptron can demonstrate a fundamental type of pattern recognition in which data points are classified as belonging to one of two groups. For instance, imagine you have a dataset of plants and want to identify them as either xerophytes (plants that have evolved to survive in an environment with little water and lots of sunlight, like the desert) or hydrophytes (plants that have adapted to living submerged in water, with reduced light). That’s how I’ll use my perceptron in this section.\nOne way to approach classifying the plants is to plot their data on a 2D graph and treat the problem as a spatial one. On the x-axis, plot the amount of daily sunlight received by the plant, and on the y-axis, plot the amount of water. Once all the data has been plotted, it’s easy to draw a line across the graph, with all the xerophytes on one side and all the hydrophytes on the other, as in Figure 10.4. (I’m simplifying a little here. Real-world data would probably be messier, making the line harder to draw.) That’s how each plant can be classified. Is it below the line? Then it’s a xerophyte. Is it above the line? Then it’s a hydrophyte.\n\n  \n  Figure 10.4: A collection of points in 2D space divided by a line, representing plant categories according to their water and sunlight intake\n\nIn truth, I don’t need a neural network—not even a simple perceptron—to tell me whether a point is above or below a line. I can see the answer for myself with my own eyes, or have my computer figure it out with simple algebra. But just like solving a problem with a known answer—“to be or not to be”—was a convenient first test for the GA in Chapter 9, training a perceptron to categorize points as being on one side of a line versus the other will be a valuable way to demonstrate the algorithm of the perceptron and verify that it’s working properly.\nTo solve this problem, I’ll give my perceptron two inputs: x_0 is the x-coordinate of a point, representing a plant’s amount of sunlight, and x_1 is the y-coordinate of that point, representing the plant’s amount of water. The perceptron then guesses the plant’s classification according to the sign of the weighted sum of these inputs. If the sum is positive, the perceptron outputs a +1, signifying a hydrophyte (above the line). If the sum is negative, it outputs a –1, signifying a xerophyte (below the line). Figure 10.5 shows this perceptron (note the shorthand of w_0 and w_1 for the weights).\n\n  \n  Figure 10.5: A perceptron with two inputs (x_0 and x_1), a weight for each input (w_0 and w_1), and a processing neuron that generates the output\n\nThis scheme has a pretty significant problem, however. What if my data point is (0, 0), and I send\nthis point into the perceptron as inputs x_0 = 0 and x_1=0? No matter what the weights are, multiplication by 0 is 0. The weighted inputs are therefore still 0, and their sum will be 0 too. And the sign of 0 is . . . hmmm, there’s that deep philosophical quandary again. Regardless of how I feel about it, the point (0, 0) could certainly be above or below various lines in a 2D world. How is the perceptron supposed to interpret it accurately?\nTo avoid this dilemma, the perceptron requires a third input, typically referred to as a bias input. This extra input always has the value of 1 and is also weighted. Figure 10.6 shows the perceptron with the addition of the bias.\n\n  \n  Figure 10.6: Adding a bias input, along with its weight, to the perceptron\n\nHow does this affect point (0, 0)?\n\n  \n    \n      Input\n      Weight\n      Result\n    \n  \n  \n    \n      0\n      w_0\n      0\n    \n    \n      0\n      w_1\n      0\n    \n    \n      1\n      w_\\text{bias}\n      w_\\text{bias}\n    \n  \n\nThe output is then the sum of the weighted results: 0 + 0 + w_\\text{bias}. Therefore, the bias by itself answers the question of where (0, 0) is in relation to the line. If the bias’s weight is positive, (0, 0) is above the line; if negative, it’s below. The extra input and its weight bias the perceptron’s understanding of the line’s position relative to (0, 0)!\nThe Perceptron Code\nI’m now ready to assemble the code for a Perceptron class. The perceptron needs to track only the input weights, which I can store using an array:\n\n  class Perceptron {\n  constructor() {\n    this.weights = [];\n  }\n\nThe constructor can receive an argument indicating the number of inputs (in this case, three: x_0, x_1, and a bias) and size the weights array accordingly, filling it with random values to start:\n\n  \t// The argument <code>n</code> determines the number of inputs (including the bias).\n  constructor(n) {\n    this.weights = [];\n    for (let i = 0; i < n; i++) {\n      //{!1} The weights are picked randomly to start.\n      this.weights[i] = random(-1, 1);\n    }\n  }\n\nA perceptron’s job is to receive inputs and produce an output. These requirements can be packaged together in a feedForward() method. In this example, the perceptron’s inputs are an array (which should be the same length as the array of weights), and the output is a number, +1 or –1, as returned by the activation function based on the sign of the sum:\n\n    feedForward(inputs) {\n    let sum = 0;\n    for (let i = 0; i < this.weights.length; i++) {\n      sum += inputs[i] * this.weights[i];\n    }\n    //{!1} The result is the sign of the sum, –1 or +1.\n    // Here the perceptron is making a guess:\n    // Is it on one side of the line or the other?\n    return this.activate(sum);\n  }\n}\n\nPresumably, I could now create a Perceptron object and ask it to make a guess for any given point, as in Figure 10.7.\n\n  \n  Figure 10.7: An (x, y) coordinate from the 2D space is the input to the perceptron.\n\nHere’s the code to generate a guess:\n// Create the perceptron.\nlet perceptron = new Perceptron(3);\n// The input is three values: <em>x</em>, <em>y</em>, and the bias.\nlet inputs = [50, -12, 1];\n// The answer!\nlet guess = perceptron.feedForward(inputs);\nDid the perceptron get it right? Maybe yes, maybe no. At this point, the perceptron has no better than a 50/50 chance of arriving at the correct answer, since each weight starts out as a random value. A neural network isn’t a magic tool that can automatically guess correctly on its own. I need to teach it how to do so!\nTo train a neural network to answer correctly, I’ll use the supervised learning method I described earlier in the chapter. Remember, this technique involves giving the network inputs with known answers. This enables the network to check whether it has made a correct guess. If not, the network can learn from its mistake and adjust its weights. The process is as follows:\n\n  Provide the perceptron with inputs for which there is a known answer.\n  Ask the perceptron to guess an answer.\n  Compute the error. (Did it get the answer right or wrong?)\n\n\n  \n    Adjust all the weights according to the error.\n    Return to step 1 and repeat!\n  \n\nThis process can be packaged into a method on the Perceptron class, but before I can write it, I need to examine steps 3 and 4 in more detail. How do I define the perceptron’s error? And how should I adjust the weights according to this error?\nThe perceptron’s error can be defined as the difference between the desired answer and its guess:\n\\text{error} = \\text{desired output} - \\text{guess output}\nDoes this formula look familiar? Think back to the formula for a vehicle’s steering force that I worked out in Chapter 5:\n\\text{steering} = \\text{desired velocity} - \\text{current velocity}\nThis is also a calculation of an error! The current velocity serves as a guess, and the error (the steering force) indicates how to adjust the velocity in the correct direction. Adjusting a vehicle’s velocity to follow a target is similar to adjusting the weights of a neural network toward the correct answer.\nFor the perceptron, the output has only two possible values: +1 or –1. Therefore, only three errors are possible. If the perceptron guesses the correct answer, the guess equals the desired output and the error is 0. If the correct answer is –1 and the perceptron guessed +1, then the error is –2. If the correct answer is +1 and the perceptron guessed –1, then the error is +2. Here’s that process summarized in a table:\n\n  \n    \n      Desired\n      Guess\n      Error\n    \n  \n  \n    \n      –1\n      –1\n      0\n    \n    \n      –1\n      +1\n      –2\n    \n    \n      +1\n      –1\n      +2\n    \n    \n      +1\n      +1\n      0\n    \n  \n\nThe error is the determining factor in how the perceptron’s weights should be adjusted. For any given weight, what I’m looking to calculate is the change in weight, often called \\Delta\\text{weight} (or delta weight, \\Delta being the Greek letter delta):\n\\text{new weight} = \\text{weight} + \\Delta\\text{weight}\nTo calculate \\Delta\\text{weight}, I need to multiply the error by the input:\n\\Delta\\text{weight} = \\text{error} \\times \\text{input}\nTherefore, the new weight is calculated as follows:\n\\text{new weight} = \\text{weight} + \\text{error} \\times \\text{input}\nTo understand why this works, think again about steering. A steering force is essentially an error in velocity. By applying a steering force as an acceleration (or \\Delta\\text{velocity}), the velocity is adjusted to move in the correct direction. This is what I want to do with the neural network’s weights. I want to adjust them in the right direction, as defined by the error.\nWith steering, however, I had an additional variable that controlled the vehicle’s ability to steer: the maximum force. A high maximum force allowed the vehicle to accelerate and turn quickly, while a lower force resulted in a slower velocity adjustment. The neural network will use a similar strategy with a variable called the learning constant:\n\\text{new weight} = \\text{weight} + (\\text{error} \\times \\text{input}) \\times \\text{learning constant}\nA high learning constant causes the weight to change more drastically. This may help the perceptron arrive at a solution more quickly, but it also increases the risk of overshooting the optimal weights. A small learning constant will adjust the weights more slowly and require more training time, but will allow the network to make small adjustments that could improve overall accuracy.\nAssuming the addition of a learningConstant property to the Perceptron class, I can now write a training method for the perceptron following the steps I outlined earlier:\n  // Step 1: Provide the inputs and known answer.\n  // These are passed in as arguments to <code>train()</code>.\n  train(inputs, desired) {\n    // Step 2: Guess according to those inputs.\n    let guess = this.feedforward(inputs);\n    // Step 3: Compute the error (the difference between <code>desired</code> and <code>guess</code>).\n    let error = desired - guess;\n    //{!3} Step 4: Adjust all the weights according to the error and learning constant.\n    for (let i = 0; i < this.weights.length; i++) {\n      this.weights[i] = this.weights[i] + error * inputs[i] * this.learningConstant;\n    }\n  }\nHere’s the Perceptron class as a whole:\nclass Perceptron {\n  constructor(totalInputs) {\n    //{!2} The perceptron stores its weights and learning constants.\n    this.weights = [];\n    this.learningConstant = 0.01;\n    //{!3} The weights start off random.\n    for (let i = 0; i < totalInputs; i++) {\n      this.weights[i] = random(-1, 1);\n    }\n  }\n\n  //{!7} Return an output based on inputs.\n  feedforward(inputs) {\n    let sum = 0;\n    for (let i = 0; i < this.weights.length; i++) {\n      sum += inputs[i] * this.weights[i];\n    }\n    return this.activate(sum);\n  }\n\n  // The output is a +1 or –1.\n  activate(sum) {\n    if (sum > 0) {\n      return 1;\n    } else {\n      return -1;\n    }\n  }\n\n  //{!4} Train the network against known data.\n  train(inputs, desired) {\n    let guess = this.feedforward(inputs);\n    let error = desired - guess;\n    for (let i = 0; i < this.weights.length; i++) {\n      //{!3.continue}\n      this.weights[i] = this.weights[i] + error * inputs[i] * this.learningConstant;\n    }\n  }\n}\nTo train the perceptron, I need a set of inputs with known answers. However, I don’t happen to have a real-world dataset (or time to research and collect one) for the xerophytes and hydrophytes scenario. In truth, though, the purpose of this demonstration isn’t to show you how to classify plants. It’s about how a perceptron can learn whether points are above or below a line on a graph, and so any set of points will do. In other words, I can just make up the data.\nWhat I’m describing is an example of synthetic data, artificially generated data that’s often used in machine learning to create controlled scenarios for training and testing. In this case, my synthetic data will consist of a set of random input points, each with a known answer indicating whether the point is above or below a line. To define the line and generate the data, I’ll use simple algebra. This approach allows me to clearly demonstrate the training process and show how the perceptron learns.\nThe question therefore becomes, how do I pick a point and know whether it’s above or below a line (without a neural network, that is)? A line can be described as a collection of points, where each point’s y-coordinate is a function of its x-coordinate:\ny = f(x)\nFor a straight line (specifically, a linear function), the relationship can be written like this:\ny = mx + b\nHere m is the slope of the line, and b is the value of y when x is 0 (the y-intercept). Here’s a specific example, with the corresponding graph in Figure 10.8.\ny = \\frac{1}2x - 1\n\n  \n  Figure 10.8: A graph of y = \\frac{1}2x - 1\n\nI’ll arbitrarily choose that as the equation for my line, and write a function accordingly:\n// A function to calculate <code>y</code> based on <code>x</code> along a line\nfunction f(x) {\n  return 0.5 * x - 1;\n}\nNow there’s the matter of the p5.js canvas defaulting to (0, 0) in the top-left corner with the y-axis pointing down. For this discussion, I’ll assume I’ve built the following into the code to reorient the canvas to match a more traditional Cartesian space.\n\n  // Move the origin <code>(0, 0)</code> to the center.\ntranslate(width / 2, height / 2);\n// Flip the y-axis orientation (positive points up!).\nscale(1, -1);\n\nI can now pick a random point in the 2D space:\nlet x = random(-100, 100);\nlet y = random(-100, 100);\nHow do I know if this point is above or below the line? The line function f(x) returns the y value on the line for that x-position. I’ll call that y_\\text{line}:\n// The <code>y</code> position on the line\nlet yline = f(x);\nIf the y value I’m examining is above the line, it will be greater than y_\\text{line}, as in Figure 10.9.\n\n  \n  Figure 10.9: If y_\\text{line} is less than y, the point is above the line.\n\nHere’s the code for that logic:\n// Start with a value of –1.\nlet desired = -1;\nif (y > yline) {\n  //{!1} The answer becomes +1 if <code>y</code> is above the line.\n  desired = 1;\n}\nI can then make an input array to go with the desired output:\n// Don’t forget to include the bias!\nlet trainingInputs = [x, y, 1];\nAssuming that I have a perceptron variable, I can train it by providing the inputs along with the desired answer:\nperceptron.train(trainingInputs, desired);\nIf I train the perceptron on a new random point (and its answer) for each cycle through draw(), it will gradually get better at classifying the points as above or below the line.\n\n  Example 10.1: The Perceptron\n  \n    \n    \n  \n\n// The perceptron\nlet perceptron;\n//{!1} An array for training data\nlet training = [];\n// A counter to track training data points one by one\nlet count = 0;\n\n//{!3} The formula for a line\nfunction f(x) {\n  return 0.5 * x + 1;\n}\n\nfunction setup() {\n  createCanvas(640, 240);\n  // The perceptron has three inputs (including bias) and a learning rate of 0.0001.\n  perceptron = new Perceptron(3, 0.0001);\n  //{!1} Make 2,000 training data points.\n  for (let i = 0; i < 2000; i++) {\n    let x = random(-width / 2, width / 2);\n    let y = random(-height / 2, height / 2);\n    training[i] = [x, y, 1];\n  }\n}\n\nfunction draw() {\n  background(255);\n  // Reorient the canvas to match a traditional Cartesian plane.\n  translate(width / 2, height / 2);\n  scale(1, -1);\n  // Draw the line.\n  stroke(0);\n  strokeWeight(2);\n  line(-width / 2, f(-width / 2), width / 2, f(width / 2));\n  // Get the current <code>(x, y)</code> of the training data.\n  let x = training[count][0];\n  let y = training[count][1];\n  // What is the desired output?\n  let desired = -1;\n  if (y > f(x)) {\n    desired = 1;\n  }\n  // Train the perceptron.\n  perceptron.train(training[count], desired);\n  // For animation, train one point at a time.\n  count = (count + 1) % training.length;\n  // Draw all the points and color according to the output of the perceptron.\n  for (let dataPoint of training) {\n    let guess = perceptron.feedforward(dataPoint);\n    if (guess > 0) {\n      fill(127);\n    } else {\n      fill(255);\n    }\n    strokeWeight(1);\n    stroke(0);\n    circle(dataPoint[0], dataPoint[1], 8);\n  }\n}\nIn Example 10.1, the training data is visualized alongside the target solution line. Each point represents a piece of training data, and its color is determined by the perceptron’s current classification—gray for +1 or white for –1. I use a small learning constant (0.0001) to slow down how the system refines its classifications over time.\nAn intriguing aspect of this example lies in the relationship between the perceptron’s weights and the characteristics of the line dividing the points—specifically, the line’s slope and y-intercept (the m and b in y = mx + b). The weights in this context aren’t just arbitrary or “magic” values; they bear a direct relationship to the geometry of the dataset. In this case, I’m using just 2D data, but for many machine learning applications, the data exists in much higher-dimensional spaces. The weights of a neural network help navigate these spaces, defining hyperplanes or decision boundaries that segment and classify the data.\n\n  Exercise 10.1\n  Modify the code from Example 10.1 to also draw the perceptron’s current decision boundary during the training process—its best guess for where the line should be. Hint: Use the perceptron’s current weights to calculate the line’s equation.\n\nWhile this perceptron example offers a conceptual foundation, real-world datasets often feature more diverse and dynamic ranges of input values. For the simplified scenario here, the range of values for x is larger than that for y because of the canvas size of 640\\times240. Despite this, the example still works—after all, the sign activation function doesn’t rely on specific input ranges, and it’s such a straightforward binary classification task.\nHowever, real-world data often has much greater complexity in terms of input ranges. To this end, data normalization is a critical step in machine learning. Normalizing data involves mapping the training data to ensure that all inputs (and outputs) conform to a uniform range—typically 0 to 1, or perhaps –1 to 1. This process can improve training efficiency and prevent individual inputs from dominating the learning process. In the next section, using the ml5.js library, I’ll build data normalization into the process.\n\n  Exercise 10.2\n  Instead of using supervised learning, can you train the neural network to find the right weights by using a GA?\n\n\n  Exercise 10.3\n  Incorporate data normalization into the example. Does this improve the learning efficiency?\n\nPutting the “Network” in Neural Network\n\n\nA perceptron can have multiple inputs, but it’s still just a single, lonely neuron. Unfortunately, that limits the range of problems it can solve. The true power of neural networks comes from the network part. Link multiple neurons together and you’re able to solve problems of much greater complexity.\nIf you read an AI textbook, it will say that a perceptron can solve only linearly separable problems. If a dataset is linearly separable, you can graph it and classify it into two groups simply by drawing a straight line (see Figure 10.10, left). Classifying plants as xerophytes or hydrophytes is a linearly separable problem.\n\n  \n  Figure 10.10: Data points that are linearly separable (left) and data points that are nonlinearly separable, as a curve is required to separate the points (right)\n\nNow imagine you’re classifying plants according to soil acidity (x-axis) and temperature (y-axis). Some plants might thrive in acidic soils but only within a narrow temperature range, while other plants prefer less acidic soils but tolerate a broader range of temperatures. A more complex relationship exists between the two variables, so a straight line can’t be drawn to separate the two categories of plants, acidophilic and alkaliphilic (see Figure 10.10, right). A lone perceptron can’t handle this type of nonlinearly separable problem. (Caveat here: I’m making up these scenarios. If you happen to be a botanist, please let me know if I’m anywhere close to reality.)\nOne of the simplest examples of a nonlinearly separable problem is XOR (exclusive or). This is a logical operator, similar to the more familiar AND and OR. For A AND B to be true, both A and B must be true. With OR, either A or B (or both) can be true. These are both linearly separable problems. The truth tables in Figure 10.11 show their solution space. Each true or false value in the table shows the output for a particular combination of true or false inputs. See how you can draw a straight line to separate the true outputs from the false ones?\n\n  \n  Figure 10.11: Truth tables for the AND and OR logical operators. The true and false outputs can be separated by a line.\n\n\n  The XOR operator is the equivalent of (OR) AND (NOT AND). In other words, A XOR B evaluates to true only if one of the inputs is true. If both inputs are false or both are true, the output is false. To illustrate, let’s say you’re having pizza for dinner. You love pineapple on pizza, and you love mushrooms on pizza, but put them together—yech! And plain pizza, that’s no good either!\n\nThe XOR truth table in Figure 10.12 isn’t linearly separable. Try to draw a straight line to separate the true outputs from the false ones—you can’t!\n\n  \n  Figure 10.12: The truth tables for whether you want to eat the pizza (left) and XOR (right). Note how the true and false outputs can’t be separated by a single line.\n\nThe fact that a perceptron can’t even solve something as simple as XOR may seem extremely limiting. But what if I made a network out of two perceptrons? If one perceptron can solve the linearly separable OR and one perceptron can solve the linearly separate NOT AND, then two perceptrons combined can solve the nonlinearly separable XOR.\nWhen you combine multiple perceptrons, you get a multilayered perceptron, a network of many neurons (see Figure 10.13). Some are input neurons and receive the initial inputs, some are part of what’s called a hidden layer (as they’re connected to neither the inputs nor the outputs of the network directly), and then there are the output neurons, from which the results are read.\nUp until now, I’ve been visualizing a singular perceptron with one circle representing a neuron processing its input signals. Now, as I move on to larger networks, it’s more typical to represent\nall the elements (inputs, neurons, outputs) as circles, with arrows that indicate the flow of data. In Figure 10.13, you can see the inputs and bias flowing into the hidden layer, which then flows to the output.\n\n  \n  Figure 10.13: A multilayered perceptron has the same inputs and output as the simple perceptron, but now it includes a hidden layer of neurons.\n\nTraining a simple perceptron is pretty straightforward: you feed the data through and evaluate how to change the input weights according to the error. With a multilayered perceptron, however, the training process becomes more complex. The overall output of the network is still generated in essentially the same manner as before: the inputs multiplied by the weights are summed and fed forward through the various layers of the network. And you still use the network’s guess to calculate the error (desired result – guess). But now so many connections exist between layers of the network, each with its own weight. How do you know how much each neuron or connection contributed to the overall error of the network, and how it should be adjusted?\nThe solution to optimizing the weights of a multilayered network is backpropagation. This process takes the error and feeds it backward through the network so it can adjust the weights of all the connections in proportion to how much they’ve contributed to the total error. The details of backpropagation are beyond the scope of this book. The algorithm uses a variety of activation functions (one classic example is the sigmoid function) as well as some calculus. If you’re interested\nin continuing down this road and learning more about how backpropagation works, you can find\nmy “Toy Neural Network” project at the Coding Train website with accompanying video tutorials. They go through all the steps of solving XOR using a multilayered feed-forward network with backpropagation. For this chapter, however, I’d instead like to get some help and phone a friend.\nMachine Learning with ml5.js\nThat friend is ml5.js. This machine learning library can manage the details of complex processes like backpropagation so you and I don’t have to worry about them. As I mentioned earlier in the chapter, ml5.js aims to provide a friendly entry point for those who are new to machine learning and neural networks, while still harnessing the power of Google’s TensorFlow.js behind the scenes.\nTo use ml5.js in a sketch, you must import it via a <script> element in your index.html file, much as you did with Matter.js and Toxiclibs.js in Chapter 6:\n<script src=\"https://unpkg.com/ml5@1/dist/ml5.min.js\"></script>\nMy goal for the rest of this chapter is to introduce ml5.js by developing a system that can recognize mouse gestures. This will prepare you for Chapter 11, where I’ll add a neural network “brain” to an autonomous steering agent and tie machine learning back into the story of the book. First, however, I’d like to talk more generally through the steps of training a multilayered neural network model using supervised learning. Outlining these steps will highlight important decisions you’ll have to make before developing a learning model, introduce the syntax of the ml5.js library, and provide you with the context you’ll need before training your own machine learning models.\nThe Machine Learning Life Cycle\nThe life cycle of a machine learning model is typically broken into seven steps:\n\n  Collect the data. Data forms the foundation of any machine learning task. This stage might involve running experiments, manually inputting values, sourcing public data, or a myriad of other methods (like generating synthetic data).\n  Prepare the data. Raw data often isn’t in a format suitable for machine learning algorithms. It might also have duplicate or missing values, or contain outliers that skew the data. Such inconsistencies may need to be manually adjusted. Additionally, as I mentioned earlier, neural networks work best with normalized data, which has values scaled to fit within a standard range. Another key part of preparing data is separating it into distinct sets: training, validation, and testing. The training data is used to teach the model (step 4), while the validation and testing data (the distinction is subtle—more on this later) are set aside and reserved for evaluating the model’s performance (step 5).\n  Choose a model. Design the architecture of the neural network. Different models are more suitable for certain types of data and outputs.\n\n\n  \n    Train the model. Feed the training portion of the data through the model and allow the model to adjust the weights of the neural network based on its errors. This process is known as optimization: the model tunes the weights so they result in the fewest number of errors.\n  \n\n\n  Evaluate the model. Remember the testing data that was set aside in step 2? Since that data wasn’t used in training, it provides a means to evaluate how well the model performs on new, unseen data.\n  Tune the parameters. The training process is influenced by a set of parameters (often called hyperparameters) such as the learning rate, which dictates how much the model should adjust its weights based on errors in prediction. I called this the learningConstant in the perceptron example. By fine-tuning these parameters and revisiting steps 4 (training), 3 (model selection), and even 2 (data preparation), you can often improve the model’s performance.\n  Deploy the model. Once the model is trained and its performance is evaluated satisfactorily, it’s time to use the model out in the real world with new data!\n\nThese steps are the cornerstone of supervised machine learning. However, even though 7 is a truly excellent number, I think I missed one more critical step. I’ll call it step 0.\n\n  Identify the problem. This initial step defines the problem that needs solving. What is the objective? What are you trying to accomplish or predict with your machine learning model?\n\nThis zeroth step informs all the other steps in the process. After all, how are you supposed to collect your data and choose a model without knowing what you’re even trying to do? Are you predicting a number? A category? A sequence? Is it a binary choice, or are there many options? These sorts of questions often boil down to choosing between two types of tasks that the majority of machine learning applications fall into: classification and regression.\nClassification and Regression\nClassification is a type of machine learning problem that involves predicting a label (also called a category or class) for a piece of data. If this sounds familiar, that’s because it is: the simple perceptron in Example 10.1 was trained to classify points as above or below a line. To give another example, an image classifier might try to guess if a photo is of a cat or a dog and assign the corresponding label (see Figure 10.14).\n\n  \n  Figure 10.14: Labeling images as cats or dogs\n\nClassification doesn’t happen by magic. The model must first be shown many examples of dogs and cats with the correct labels in order to properly configure the weights of all the connections. This is the training part of supervised learning.\nThe classic “Hello, world!” demonstration of machine learning and supervised learning is a classification problem of the MNIST dataset. Short for Modified National Institute of Standards and Technology, MNIST is a dataset that was collected and processed by Yann LeCun (Courant Institute, NYU), Corinna Cortes (Google Labs), and Christopher J.C. Burges (Microsoft Research). Widely used for training and testing in the field of machine learning, this dataset consists of 70,000 handwritten digits from 0 to 9; each is a 28\\times28-pixel grayscale image (see Figure 10.15 for examples). Each image is labeled with its corresponding digit.\n\n  \n  Figure 10.15: A selection of handwritten digits 0–9 from the MNIST dataset (courtesy of Suvanjanprasai)\n\nMNIST is a canonical example of a training dataset for image classification: the model has a discrete number of categories to choose from (10 to be exact—no more, no less). After the model is trained on the 70,000 labeled images, the goal is for it to classify new images and assign the appropriate label, a digit from 0 to 9.\nRegression, on the other hand, is a machine learning task for which the prediction is a continuous value, typically a floating-point number. A regression problem can involve multiple outputs, but thinking about just one is often simpler to start. For example, consider a machine learning model that predicts the daily electricity usage of a house based on input factors like the number of occupants, the size of the house, and the temperature outside (see Figure 10.16).\n\n  \n  Figure 10.16: Factors like weather and the size and occupancy of a home can influence its daily electricity usage.\n\nRather than picking from a discrete set of output options, the goal of the neural network is now to guess a number—any number. Will the house use 30.5 kilowatt-hours of electricity that day? Or 48.7 kWh? Or 100.2 kWh? The output prediction could be any value from a continuous range.\nNetwork Design\nKnowing what problem you’re trying to solve (step 0) also has a significant bearing on the design of the neural network—in particular, on its input and output layers. I’ll demonstrate with another classic “Hello, world!” classification example from the field of data science and machine learning: the iris dataset. This dataset, which can be found in the Machine Learning Repository at the University of California, Irvine, originated from the work of American botanist Edgar Anderson.\nAnderson collected flower data over many years across multiple regions of the United States and Canada. For more on the origins of this famous dataset, see “The Iris Data Set: In Search of the Source of Virginica” by Antony Unwin and Kim Kleinman. After carefully analyzing the data, Anderson built a table to classify iris flowers into three distinct species: Iris setosa, Iris versicolor, and Iris virginica (see Figure 10.17).\n\n  \n  Figure 10.17: Three distinct species of iris flowers\n\nAnderson included four numeric attributes for each flower: sepal length, sepal width, petal length, and petal width, all measured in centimeters. (He also recorded color information, but that data appears to have been lost.) Each record is then paired with the appropriate iris categorization:\n\n  \n    \n      Sepal Length\n      Sepal Width\n      Petal Length\n      Petal Width\n      Classification\n    \n  \n  \n    \n      5.1\n      3.5\n      1.4\n      0.2\n      Iris setosa\n    \n    \n      4.9\n      3.0\n      1.4\n      0.2\n      Iris setosa\n    \n    \n      7.0\n      3.2\n      4.7\n      1.4\n      Iris versicolor\n    \n    \n      6.4\n      3.2\n      4.5\n      1.5\n      Iris versicolor\n    \n    \n      6.3\n      3.3\n      6.0\n      2.5\n      Iris virginica\n    \n    \n      5.8\n      2.7\n      5.1\n      1.9\n      Iris virginica\n    \n  \n\nIn this dataset, the first four columns (sepal length, sepal width, petal length, petal width) serve as inputs to the neural network. The output is the classification provided in the fifth column. Figure 10.18 depicts a possible architecture for a neural network that can be trained on this data.\n\n  \n  Figure 10.18: A possible network architecture for iris classification\n\nOn the left are the four inputs to the network, corresponding to the first four columns of the data table. On the right are three possible outputs, each representing one of the iris species labels. In between is the hidden layer, which, as mentioned earlier, adds complexity to the network’s architecture, necessary for handling nonlinearly separable data. Each node in the hidden layer is connected to every node that comes before and after it. This is commonly called a fully connected or dense layer.\nYou might also notice the absence of explicit bias nodes in this diagram. While biases play an important role in the output of each neuron, they’re often left out of visual representations to keep the diagrams clean and focused on the primary data flow. (The ml5.js library will ultimately manage the biases for me internally.)\nThe neural network’s goal is to “activate” the correct output for the input data, just as the perceptron would output a +1 or –1 for its single binary classification. In this case, the output values are like signals that help the network decide which iris species label to assign. The highest computed value activates to signify the network’s best guess about the classification.\nThe key takeaway here is that a classification network should have as many inputs as there are values for each item in the dataset, and as many outputs as there are categories. As for the hidden layer, the design is much less set in stone. The hidden layer in Figure 10.18 has five nodes, but this number is entirely arbitrary. Neural network architectures can vary greatly, and the number of hidden nodes is often determined through trial and error or other educated guessing methods (called heuristics). In the context of this book, I’ll be relying on ml5.js to automatically configure the architecture based on the input and output data.\nWhat about the inputs and outputs in a regression scenario, like the household electricity consumption example I mentioned earlier? I’ll go ahead and make up a dataset for this scenario,\nwith values representing the occupants and size of the house, the day’s temperature, and the corresponding electricity usage. This is much like a synthetic dataset, given that it’s not data collected for a real-world scenario—but whereas synthetic data is generated automatically, here I’m manually inputting numbers from my own imagination:\n\n  \n    \n      Occupants\n      Size (m²)\n      Temperature Outside (°C)\n      Electricity Usage (kWh)\n    \n    \n      4\n      150\n      24\n      25.3\n    \n    \n      2\n      100\n      25.5\n      16.2\n    \n    \n      1\n      70\n      26.5\n      12.1\n    \n    \n      4\n      120\n      23\n      22.1\n    \n    \n      2\n      90\n      21.5\n      15.2\n    \n    \n      5\n      180\n      20\n      24.4\n    \n    \n      1\n      60\n      18.5\n      11.7\n    \n  \n\nThe neural network for this problem should have three input nodes corresponding to the first three columns (occupants, size, temperature). Meanwhile, it should have one output node representing the fourth column, the network’s guess about the electricity usage. And I’ll arbitrarily say the network’s hidden layer should have four nodes rather than five. Figure 10.19 shows this network architecture.\n\n  \n  Figure 10.19: A possible network architecture for three inputs and one regression output\n\nUnlike the iris classification network, which is choosing from three labels and therefore has three outputs, this network is trying to predict just one number, so it has only one output. I’ll note, however, that a single output isn’t a requirement of regression. A machine learning model can also perform a regression that predicts multiple continuous values, in which case the model would have multiple outputs.\nml5.js Syntax\nThe ml5.js library is a collection of machine learning models that can be accessed using the syntax ml5.functionName(). For example, to use a pretrained model that detects hand positions, you can use ml5.handPose(). For classifying images, you can use ml5.imageClassifier(). While I encourage you to explore all that ml5.js has to offer (I’ll reference some of these pretrained models in upcoming exercise ideas), for this chapter I’ll focus on only one function in ml5.js, ml5.neuralNetwork(), which creates an empty neural network for you to train.\nTo use this function, you must first create a JavaScript object that will configure the model being created. Here’s where some of the big-picture factors I just discussed—is this a classification or a regression task? How many inputs and outputs?—come into play. I’ll begin by specifying the task I want the model to perform (\"regression\" or \"classification\"):\nlet options = { task: \"classification\" };\nlet classifier = ml5.neuralNetwork(options);\nThis, however, gives ml5.js little to go on in terms of designing the network architecture. Adding the inputs and outputs will complete the rest of the puzzle. The iris flower classification has four inputs and three possible output labels. This can be configured as part of the options object with a single integer for the number of inputs and an array of strings listing the output labels:\nlet options = {\n  inputs: 4,\n  outputs: [\"iris-setosa\", \"iris-virginica\", \"iris-versicolor\"],\n  task: \"classification\",\n};\nlet digitClassifier = ml5.neuralNetwork(options);\nThe electricity regression scenario had three input values (occupants, size, temperature) and one output value (usage in kWh). With regression, there are no string output labels, so only an integer indicating the number of outputs is required:\nlet options = {\n  inputs: 3,\n  outputs: 1,\n  task: \"regression\",\n};\nlet energyPredictor = ml5.neuralNetwork(options);\nYou can set many other properties of the model through the options object. For example, you could specify the number of hidden layers between the inputs and outputs (there are typically several), the number of neurons in each layer, which activation functions to use, and more. In most cases, however, you can leave out these extra settings and let ml5.js make its best guess on how to design the model based on the task and data at hand.\nBuilding a Gesture Classifier\nI’ll now walk through the steps of the machine learning life cycle with an example problem well\nsuited for p5.js, building all the code for each step along the way using ml5.js. I’ll begin at step 0 by articulating the problem. Imagine for a moment that you’re working on an interactive application that responds to gestures. Maybe the gestures are ultimately meant to be recorded via body tracking, but you want to start with something much simpler—a single stroke of the mouse (see Figure 10.20).\n\n  \n  Figure 10.20: A single mouse gesture as a vector between a start and end point\n\nEach gesture could be recorded as a vector extending from the start to the end point of a mouse movement. The x- and y-components of the vector will be the model’s inputs. The model’s task could be to predict one of four possible labels for the gesture: up, down, left, or right. With a discrete set of possible outputs, this sounds like a classification problem. The four labels will be the model’s outputs.\nMuch like some of the GA demonstrations in Chapter 9—and like the simple perceptron example earlier in this chapter—the problem I’m selecting here has a known solution and could be solved more easily and efficiently without a neural network. The direction of a vector can be classified with the heading() function and a series of if statements! However, by using this seemingly trivial scenario, I hope to explain the process of training a machine learning model in an understandable and friendly way. Additionally, this example will make it easy to check that the code is working as expected. When I’m done, I’ll provide some ideas about how to expand the classifier to a scenario that couldn’t use simple if statements.\nCollecting and Preparing the Data\nWith the problem established, I can turn to steps 1 and 2: collecting and preparing the data. In the real world, these steps can be tedious, especially when the raw data you collect is messy and needs a lot of initial processing. You can think of this like having to organize, wash, and chop all your ingredients before you can start cooking a meal from scratch.\nFor simplicity, I’d instead like to take the approach of ordering a machine learning “meal kit,” with the ingredients (data) already portioned and prepared. This way, I’ll get straight to the cooking itself, the process of training the model. After all, this is really just an appetizer for what will be the ultimate meal in Chapter 11, when I apply neural networks to steering agents.\nWith that in mind, I’ll handcode some example data and manually keep it normalized within a range of –1 and +1. I’ll organize the data into an array of objects, pairing the x- and y-components of a vector with a string label. I’m picking values that I feel clearly point in a specific direction and assigning the appropriate label—two examples per label:\nlet data = [\n  { x: 0.99, y: 0.02, label: \"right\" },\n  { x: 0.76, y: -0.1, label: \"right\" },\n  { x: -1.0, y: 0.12, label: \"left\" },\n  { x: -0.9, y: -0.1, label: \"left\" },\n  { x: 0.02, y: 0.98, label: \"down\" },\n  { x: -0.2, y: 0.75, label: \"down\" },\n  { x: 0.01, y: -0.9, label: \"up\" },\n  { x: -0.1, y: -0.8, label: \"up\" },\n];\nFigure 10.21 shows the same data expressed as arrows.\n\n  \n  Figure 10.21: The input data visualized as vectors (arrows)\n\nIn a more realistic scenario, I’d probably have a much larger dataset that would be loaded in from a separate file, instead of written directly into the code. For example, JavaScript Object Notation (JSON) and comma-separated values (CSV) are two popular formats for storing and loading data. JSON stores data in key-value pairs and follows the same exact format as JavaScript object literals. CSV is a file format that stores tabular data (like a spreadsheet). You could use numerous other data formats, depending on your needs and the programming environment you’re working with.\nIn the real world, the values in that larger dataset would actually come from somewhere. Maybe I would collect the data by asking users to perform specific gestures and recording their inputs, or by writing an algorithm to automatically generate larger amounts of synthetic data that represent the idealized versions of the gestures I want the model to recognize. In either case, the key would be to collect a diverse set of examples that adequately represent the variations in how the gestures might be performed. For now, however, let’s see how it goes with just a few servings of data.\n\n  Exercise 10.4\n  Create a p5.js sketch that collects gesture data from users and saves it to a JSON file. You can use mousePressed() and mouseReleased() to mark the start and end of each gesture, and saveJSON() to download the data into a file.\n\nChoosing a Model\nI’ve now come to step 3 of the machine learning life cycle, selecting a model. This is where I’m going to start letting ml5.js do the heavy lifting for me. To create the model with ml5.js, all I need to do is specify the task, the inputs, and the outputs:\nlet options = {\n  task: \"classification\",\n  inputs: 2,\n  outputs: [\"up\", \"down\", \"left\", \"right\"],\n  debug: true\n};\nlet classifier = ml5.neuralNetwork(options);\nThat’s it! I’m done! Thanks to ml5.js, I can bypass a host of complexities such as the number of layers and neurons per layer to have, the kinds of activation functions to use, and how to set up the algorithms for training the network. The library will make these decisions for me.\nOf course, the default ml5.js model architecture may not be perfect for all cases. I encourage you to read the ml5.js documentation for additional details on how to customize the model. I’ll also point out that ml5.js is able to infer the inputs and outputs from the data, so those properties aren’t entirely necessary to include here in the options object. However, for the sake of clarity (and since I’ll need to specify them for later examples), I’m including them here.\nThe debug property, when set to true, turns on a visual interface for the training process. It’s a helpful tool for spotting potential issues during training and for getting a better understanding of what’s happening behind the scenes. You’ll see what this interface looks like later in the chapter.\nTraining the Model\nNow that I have the data in a data variable and a neural network initialized in the classifier variable, I’m ready to train the model. That process starts with adding the data to the model. And for that, it turns out I’m not quite done with preparing the data.\nRight now, my data is neatly organized in an array of objects, each containing the x- and y-components of a vector and a corresponding string label. This is a typical format for training data, but it isn’t directly consumable by ml5.js. (Sure, I could have initially organized the data into a format that ml5.js recognizes, but I’m including this extra step because it will likely be necessary when you’re using a dataset that has been collected or sourced elsewhere.) To add the data to the model, I need to separate the inputs from the outputs so that the model understands which are which.\nThe ml5.js library offers a fair amount of flexibility in the kinds of formats it will accept, but I’ll choose to use arrays—one for the inputs and one for the outputs. I can use a loop to reorganize each data item and add it to the model:\nfor (let item of data) {\n  // An array of two numbers for the inputs\n  let inputs = [item.x, item.y];\n  // A single string label for the output\n  let outputs = [item.label];\n  //{!1} Add the training data to the classifier.\n  classifier.addData(inputs, outputs);\n}\nWhat I’ve done here is set the shape of the data. In machine learning, this term describes the data’s dimensions and structure. It indicates how the data is organized in terms of rows, columns, and potentially even deeper, into additional dimensions. Understanding the shape of your data is crucial because it determines the way the model should be structured.\nHere, the input data’s shape is a 1D array containing two numbers (representing x and y). The output data, similarly, is a 1D array containing just a single string label. Every piece of data going in and out of the network will follow this pattern. While this is a small and simple example, it nicely mirrors many real-world scenarios in which the inputs are numerically represented in an array, and the outputs are string labels.\nAfter passing the data into the classifier, ml5.js provides a helper function to normalize it. As I’ve mentioned, normalizing data (adjusting the scale to a standard range) is a critical step in the machine learning process:\n// Normalize the data.\nclassifier.normalizeData();\nIn this case, the handcoded data was limited to a range of –1 to +1 from the get-go, so calling normalizeData() here is likely redundant. Still, this function call is important to demonstrate. Normalizing your data ahead of time as part of the preprocessing step will absolutely work, but the auto-normalization feature of ml5.js is a big help!\nNow for the heart of the machine learning process: actually training the model. Here’s the code:\n// The <code>train()</code> method initiates the training process.\nclassifier.train(finishedTraining);\n// A callback function for when the training is complete\nfunction finishedTraining() {\n  console.log(\"Training complete!\");\n}\nYes, that’s it! After all, the hard work has already been completed. The data was collected, prepared, and fed into the model. All that remains is to call the train() method, sit back, and let ml5.js do its thing.\nIn truth, it isn’t quite that simple. If I were to run the code as written and then test the model, the results would probably be inadequate. Here’s where another key term in machine learning comes into play: epochs. The train() method tells the neural network to start the learning process. But how long should it train for? You can think of an epoch as one round of practice, one cycle of using the entire training dataset to update the weights of the neural network. Generally speaking, the more epochs you go through, the better the network will perform, but at a certain point you’ll have diminishing returns. The number of epochs can be set by passing in an options object into train().\n//{!1} Set the number of epochs for training.\nlet options = { epochs: 25 };\nclassifier.train(options, finishedTraining);\nThe number of epochs is an example of a hyperparameter, a global setting for the training process. You can set others through the options object (the learning rate, for example), but I’m going to stick with the defaults. You can read more about customization options in the ml5.js documentation.\nThe second argument to train() is optional, but it’s good to include one. It specifies a callback function that runs when the training process is complete—in this case, finishedTraining(). (See the “Callbacks” box for more on callback functions.) This is useful for knowing when you can proceed to the next steps in your code. Another optional callback, which I usually name whileTraining(), is triggered after each epoch. However, for my purposes, knowing when the training is done is plenty!\n\n  Callbacks\n  A callback function in JavaScript is a function you don’t actually call yourself. Instead, you provide it as an argument to another function, intending for it to be called back automatically at a later time (typically associated with an event, like a mouse click). You’ve seen this before when working with Matter.js in Chapter 6, where you specified a function to call whenever a collision was detected.\n  Callbacks are needed for asynchronous operations, when you want your code to continue along with animating or doing other things while waiting for another task (like training a machine learning model) to finish. A classic example of this in p5.js is loading data into a sketch with loadJSON().\n  JavaScript also provides a more recent approach for handling asynchronous operations known as promises. With promises, you can use keywords like async and await to make your asynchronous code look more like traditional synchronous code. While ml5.js also supports this style, I’ll stick to using callbacks to stay aligned with p5.js style.\n\nEvaluating the Model\nIf debug is set to true in the initial call to ml5.neuralNetwork(), a visual interface should appear after train() is called, covering most of the p5.js page and canvas (see Figure 10.22). This interface, called the Visor, represents the evaluation step.\n\n  \n  Figure 10.22: The Visor, with a graph of the loss function and model details\n\nThe Visor comes from TensorFlow.js (which underlies ml5.js) and includes a graph that provides real-time feedback on the progress of the training. This graph plots the loss of the model on the y-axis against the number of epochs along the x-axis. Loss is a measure of how far off the model’s predictions are from the correct outputs provided by the training data. It quantifies the model’s total error. When training begins, it’s common for the loss to be high because the model has yet to learn anything. Ideally, as the model trains through more epochs, it should get better at its predictions, and the loss should decrease. If the graph goes down as the epochs increase, this is a good sign!\nRunning the training for the 200 epochs depicted in Figure 10.21 might strike you as a bit excessive. In a real-world scenario with more extensive data, I would probably use fewer epochs, like the 25 I specified in the original code snippet. However, because the dataset here is so tiny, the higher number of epochs helps the model get enough practice with the data. Remember, this is a toy example, aiming to make the concepts clear rather than to produce a sophisticated machine learning model.\nBelow the graph, the Visor shows a Model Summary table with details on the lower-level TensorFlow.js model architecture created behind the scenes. The summary includes layer names, neuron counts per layer (in the Output Shape column), and a parameters count, which is the total number of weights, one for each connection between two neurons. In this case, dense_Dense1 is the hidden layer with 16 neurons (a number chosen by ml5.js), and dense_Dense2 is the output layer with 4 neurons, one for each classification category. (TensorFlow.js doesn’t think of the inputs as a distinct layer; rather, they’re merely the starting point of the data flow.) The batch in the Output Shape column doesn’t refer to a specific number but indicates that the model can process a variable amount of training data (a batch) for any single cycle of model training.\nBefore moving on from the evaluation stage, I have a loose end to tie up. When I first outlined the steps of the machine learning life cycle, I mentioned that preparing the data typically involves splitting the dataset into three parts to help with the evaluation process:\n\n  Training: The primary dataset used to train the model\n  Validation: A subset of the data used to check the model during training, typically at the end of each epoch\n  Testing: Additional untouched data never considered during the training process, for determining the model’s final performance after the training is completed\n\nYou may have noticed that I never did this. For simplicity, I’ve instead used the entire dataset for training. After all, my dataset has only eight records; it’s much too small to divide three sets! With a large dataset, this three-way split would be more appropriate.\nUsing such a small dataset risks the model overfitting the data, however: the model becomes so tuned to the specific peculiarities of the training data that it’s much less effective when working with new, unseen data. The main reason to use a validation set is to monitor the model during the training process. As training progresses, if the model’s accuracy improves on the training data but deteriorates on the validation data, it’s a strong indicator that overfitting might be occurring. (The testing set is reserved strictly for the final evaluation, one more chance after training is complete to gauge the model’s performance.)\nFor more realistic scenarios, ml5.js provides a way to split up the data, as well as automatic features for employing validation data. If you’re inclined to go further, you can explore the full set of neural network examples on the ml5.js website.\nTuning the Parameters\nAfter the evaluation step, there’s typically an iterative process of adjusting hyperparameters and going through training again to achieve the best performance from the model. While ml5.js offers capabilities for parameter tuning (which you can learn about in the library’s reference), it isn’t really geared toward making low-level, fine-grained adjustments to a model. Using TensorFlow.js directly might be your best bet if you want to explore this step in more detail, since it offers a broader suite of tools and allows for lower-level control over the training process.\nIn this case, tuning the parameters isn’t strictly necessary. The graph in the Visor shows a loss all the way down at 0.1, which is plenty accurate for my purposes. I’m happy to move on.\nDeploying the Model\nIt’s finally time to deploy the model and see the payoff of all that hard work. This typically involves integrating the model into a separate application to make predictions or decisions based on new, previously unseen data. For this, ml5.js offers the convenience of a save() function to download the trained model to a file from one sketch and a load() function to load it for use in a completely different sketch. This saves you from having to retrain the model from scratch every single time you need it.\nWhile a model would typically be deployed to a different sketch from the one where it was trained, I’m going to deploy the model in the same sketch for the sake of simplicity. In fact, once the training process is complete, the resulting model is, in essence, already deployed in the current sketch. It’s saved in the classifier variable and can be used to make predictions by passing the model new data through the classify() method. The shape of the data sent to classify() should match that of the input data used in training—in this case, two floating-point numbers, representing the x- and y-components of a direction vector:\n// Manually create a vector.\nlet direction = createVector(1, 0);\n// Convert the x- and y-components into an input array.\nlet inputs = [direction.x, direction.y];\n// Ask the model to classify the inputs.\nclassifier.classify(inputs, gotResults);\nThe second argument to classify() is another callback function for accessing the results:\nfunction gotResults(results) {\n  console.log(results);\n}\nThe model’s prediction arrives in the argument to the callback, which I’m calling results in the code. Inside, you’ll find an array of the possible labels, sorted by confidence, a probability value that the model assigns to each label. These probabilities represent how sure the model is of that particular prediction. They range from 0 to 1, with values closer to 1 indicating higher confidence and values near 0 suggesting lower confidence:\n[\n  {\n    \"label\": \"right\",\n    \"confidence\": 0.9669702649116516\n  },\n  {\n    \"label\": \"up\",\n    \"confidence\": 0.01878807507455349\n  },\n  {\n    \"label\": \"down\",\n    \"confidence\": 0.013948931358754635\n  },\n  {\n    \"label\": \"left\",\n    \"confidence\": 0.00029277068097144365\n  }\n]\nIn this example output, the model is highly confident (approximately 96.7 percent) that the correct label is \"right\", while it has minimal confidence (0.03 percent) in the \"left\" label. The confidence values are normalized and add up to 100 percent.\nAll that remains now is to fill out the sketch with code so the model can receive live input from the mouse. The first step is to signal the completion of the training process so the user knows the model is ready. I’ll include a global status variable to track the training process and ultimately display the predicted label on the canvas. The variable is initialized to \"training\" but updated to \"ready\" through the finishedTraining() callback.\n\n  // When the sketch starts, it will show a status of <code>training</code>.\nlet status = \"training\";\n\nfunction draw() {\n  background(255);\n  textAlign(CENTER, CENTER);\n  textSize(64);\n  text(status, width / 2, height / 2);\n}\n\n// This is the callback for when training is complete, and the message changes to <code>ready</code>.\nfunction finishedTraining() {\n  status = \"ready\";\n}\n\nFinally, I’ll use p5.js’s mouse functions to build a vector while the mouse is being dragged and call classifier.classify() on that vector when the mouse is clicked.\n\n  Example 10.2: Gesture Classifier\n  \n    \n    \n  \n\n// Store the start of a gesture when the mouse is pressed.\nfunction mousePressed() {\n  start = createVector(mouseX, mouseY);\n}\n\n// Update the end of a gesture as the mouse is dragged.\nfunction mouseDragged() {\n  end = createVector(mouseX, mouseY);\n}\n\n// The gesture is complete when the mouse is released.\nfunction mouseReleased() {\n  // Calculate and normalize a direction vector.\n  let dir = p5.Vector.sub(end, start);\n  dir.normalize();\n  // Convert to an input array and classify.\n  let inputs = [dir.x, dir.y];\n  classifier.classify(inputs, gotResults);\n}\n\n// Store the resulting label in the <code>status</code> variable for showing in the canvas.\nfunction gotResults(error, results) {\n  status = results[0].label;\n}\nSince the results array is sorted by confidence, if I just want to use a single label as the prediction, I can access the first element of the array with results[0].label, as in the gotResults() function in Example 10.2. This label is passed to the status variable to be displayed on the canvas.\n\n  Exercise 10.5\n  Divide Example 10.2 into three sketches: one for collecting data, one for training, and one for deployment. Use the ml5.neuralNetwork functions save() and load() for saving and loading the model to and from a file, respectively.\n\n\n  Exercise 10.6\n  Expand the gesture-recognition model to classify a sequence of vectors, capturing more accurately the path of a longer mouse movement. Remember, your input data must have a consistent shape, so you’ll have to decide how many vectors to use to represent a gesture and store no more and no less for each data point. While this approach can work, other machine learning models (such as recurrent neural networks) are specifically designed to handle sequential data and might offer more flexibility and potential accuracy.\n\n\n  Exercise 10.7\n  One of the pretrained models in ml5.js is called Handpose. The input of the model is an image, and the prediction is a list of 21 key points—x- and y-positions, also known as landmarks—that describe a hand.\n  \n    \n    \n  \n  Can you use the outputs of the ml5.handpose() model as the inputs to an ml5.neuralNetwork() and classify various hand gestures (like a thumbs-up or thumbs-down)? For hints, you can watch my video tutorial that walks you through this process for body poses in the machine learning track on the Coding Train website.\n\n\n  The Ecosystem Project\n  Incorporate machine learning into your ecosystem to enhance the behavior of creatures. How could classification or regression be applied?\n  \n    Can you classify the creatures of your ecosystem into multiple categories? What if you use an initial population as a training dataset, and as new creatures are born, the system classifies them according to their features? What are the inputs and outputs for your system?\n    Can you use a regression to predict the life span of a creature based on its properties? Think about how size and speed affected the life span of the bloops from Chapter 9. Could you analyze how well the regression model’s predictions align with the actual outcomes?\n  \n  \n    \n    \n  \n\n\n",
  "htmlContent": "<section data-type=\"chapter\" id=\"section-neural-networks\">\n<h1 id=\"chapter-10-neural-networks\">Chapter 10. Neural Networks</h1>\n<div class=\"chapter-opening-quote\">\n  <blockquote data-type=\"epigraph\">\n    <p>The human brain has 100 billion neurons,</p>\n    <p>each neuron connected to 10 thousand</p>\n    <p>other neurons. Sitting on your shoulders</p>\n    <p>is the most complicated object</p>\n    <p>in the known universe.</p>\n    <div class=\"chapter-opening-quote-source\">\n      <p>—Michio Kaku</p>\n    </div>\n  </blockquote>\n</div>\n<div class=\"chapter-opening-figure\">\n  <figure>\n    <img src=\"/content/images/10_nn/10_nn_1.jpg\" alt>\n    <figcaption></figcaption>\n  </figure>\n  <h3 id=\"khipu-on-display-at-the-machu-picchu-museum-cusco-peru-photo-by-pi3124\"><em>Khipu</em> on display at the Machu Picchu Museum, Cusco, Peru (photo by Pi3.124)</h3>\n  <p>The <em>khipu</em> (or <em>quipu</em>) is an ancient Incan device used for recordkeeping and communication. It comprised a complex system of knotted cords to encode and transmit information. Each colored string and knot type and pattern represented specific data, such as census records or calendrical information. Interpreters, known as <em>quipucamayocs</em>, acted as a kind of accountant and decoded the stringed narrative into understandable information.</p>\n</div>\n<p>I began with inanimate objects living in a world of forces, and I gave them desires, autonomy, and the ability to take action according to a system of rules. Next, I allowed those objects, now called <em>creatures</em>, to live in a population and evolve over time. Now I’d like to ask, What is each creature’s decision-making process? How can it adjust its choices by learning over time? Can a computational entity process its environment and generate a decision?</p>\n<p>To answer these questions, I’ll once again look to nature for inspiration—specifically, the human brain. A brain can be described as a biological <strong>neural network</strong>, an interconnected web of neurons transmitting elaborate patterns of electrical signals. Within each neuron, dendrites receive input signals, and based on those inputs, the neuron fires an output signal via an axon (see Figure 10.1). Or something like that. How the human brain actually works is an elaborate and complex mystery, one that I’m certainly not going to attempt to unravel in rigorous detail in this chapter.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_2.png\" alt=\"Figure 10.1: A neuron with dendrites and an axon connected to another neuron\">\n  <figcaption>Figure 10.1: A neuron with dendrites and an axon connected to another neuron</figcaption>\n</figure>\n<p>Fortunately, as you’ve seen throughout this book, developing engaging animated systems with code doesn’t require scientific rigor or accuracy. Designing a smart rocket isn’t rocket science, and neither is designing an artificial neural network brain science. It’s enough to simply be inspired by the <em>idea</em> of brain function.</p>\n<p>In this chapter, I’ll begin with a conceptual overview of the properties and features of neural networks and build the simplest possible example of one, a network that consists of a single neuron. I’ll then introduce you to more complex neural networks by using the ml5.js library. This will serve as a foundation for <a href=\"/neuroevolution#section-neuroevolution\">Chapter 11</a>, the grand finale of this book, where I’ll combine GAs with neural networks for physics simulation.</p>\n<h2 id=\"introducing-artificial-neural-networks\">Introducing Artificial Neural Networks</h2>\n<p>Computer scientists have long been inspired by the human brain. In 1943, Warren S. McCulloch, a neuroscientist, and Walter Pitts, a logician, developed the first conceptual model of an artificial neural network. In their paper “A Logical Calculus of the Ideas Immanent in Nervous Activity,” they describe a <strong>neuron </strong>as a single computational cell living in a network of cells that receives inputs, processes those inputs, and generates an output.</p>\n<p>Their work, and the work of many scientists and researchers who followed, wasn’t meant to accurately describe how the biological brain works. Rather, an <em>artificial</em> neural network (hereafter referred to as just a <em>neural network</em>) was intended as a computational model based on the brain, designed to solve certain kinds of problems that were traditionally difficult for computers.</p>\n<p>Some problems are incredibly simple for a computer to solve but difficult for humans like you and me. Finding the square root of 964,324 is an example. A quick line of code produces the value 982, a number my computer can compute in less than a millisecond, but if you asked me to calculate that number myself, you’d be in for quite a wait. On the other hand, certain problems are incredibly simple for you or me to solve, but not so easy for a computer. Show any toddler a picture of a kitten or puppy, and they’ll quickly be able to tell you which one is which. Listen to a conversation in a noisy café and focus on just one person’s voice, and you can effortlessly comprehend their words. But need a machine to perform one of these tasks? Scientists have spent entire careers researching and implementing complex solutions, and neural networks are one of them.</p>\n<p>Here are some of the easy-for-a-human, difficult-for-a-machine applications of neural networks in software today:</p>\n<ul>\n  <li><strong>Pattern recognition:</strong> Neural networks are well suited to problems when the aim is to detect, interpret, and classify features or patterns within a dataset. This includes everything from identifying objects (like faces) in images, to optical character recognition, to more complex tasks like gesture recognition.</li>\n  <li><strong>Time-series prediction and anomaly detection: </strong>Neural networks are utilized both in forecasting, such as predicting stock market trends or weather patterns, and in recognizing anomalies, which can be applied to areas like cyberattack detection and fraud prevention.</li>\n  <li><strong>Control and adaptive decision-making systems: </strong>These applications range from autonomous vehicles like self-driving cars and drones to adaptive decision-making used in game playing, pricing models, and recommendation systems on media platforms.</li>\n  <li><strong>Signal processing and soft sensors:</strong> Neural networks play a crucial role in devices like cochlear implants and hearing aids by filtering noise and amplifying essential sounds. They’re also involved in <em>soft sensors</em>, software systems that process data from multiple sources to give a comprehensive analysis of the environment.</li>\n  <li><strong>Natural language processing (NLP):</strong> One of the biggest developments in recent years has been the use of neural networks for processing and understanding human language. They’re used in various tasks including machine translation, sentiment analysis, and text summarization, and are the underlying technology behind many digital assistants and chatbots.</li>\n  <li><strong>Generative models:</strong> The rise of novel neural network architectures has made it possible to generate new content. These systems can synthesize images, enhance image resolution, transfer style between images, and even generate music and video.</li>\n</ul>\n<p>Covering the full gamut of applications for neural networks would merit an entire book (or series of books), and by the time that book was printed, it would probably be out of date. Hopefully, this list gives you an overall sense of the features and possibilities.</p>\n<h3 id=\"how-neural-networks-work\">How Neural Networks Work</h3>\n<p>In some ways, neural networks are quite different from other computer programs. The computational systems I’ve been writing so far in this book are <strong>procedural</strong>: a program starts at the first line of code, executes it, and goes on to the next, following instructions in a linear fashion. By contrast, a true neural network doesn’t follow a linear path. Instead, information is processed collectively, in parallel, throughout a network of nodes, with each node representing a neuron. In this sense, a neural network is considered a <strong>connectionist </strong>system.</p>\n<p>In other ways, neural networks aren’t so different from some of the programs you’ve seen. A neural network exhibits all the hallmarks of a complex system, much like a cellular automaton or a flock of boids. Remember how each individual boid was simple to understand, yet by following only three rules—separation, alignment, cohesion—it contributed to complex behaviors? Each individual element in a neural network is equally simple to understand. It reads an input (a number), processes it, and generates an output (another number). That’s all there is to it, and yet a network of many neurons can exhibit incredibly rich and intelligent behaviors, echoing the complex dynamics seen in a flock of boids.</p>\n<div class=\"half-width-right\">\n  <figure>\n    <img src=\"/content/images/10_nn/10_nn_3.png\" alt=\"Figure 10.2: A neural network is a system of neurons and connections.\">\n    <figcaption>Figure 10.2: A neural network is a system of neurons and connections.</figcaption>\n  </figure>\n</div>\n<p>In fact, a neural network isn’t just a complex system, but a complex <em>adaptive</em> system, meaning it can change its internal structure based on the information flowing through it. In other words, it has the ability to learn. Typically, this is achieved by adjusting <strong>weights</strong>. In Figure 10.2, each arrow represents a connection between two neurons and indicates the pathway for the flow of information. Each connection has a weight, a number that controls the signal between the two neurons. If the network generates a <em>good</em> output (which I’ll define later), there’s no need to adjust the weights. However, if the network generates a <em>poor</em> output—an error, so to speak—then the system adapts, altering the weights with the hope of improving subsequent results.</p>\n<p>Neural networks may use a variety of strategies for learning, and I’ll focus on one of them in this chapter:</p>\n<ul>\n  <li><strong>Supervised learning:</strong> Essentially, this strategy involves a teacher that’s smarter than the network itself. Take the case of facial recognition. The teacher shows the network a bunch of faces, and the teacher already knows the name associated with each face. The network makes its guesses; then the teacher provides the network with the actual names. The network can compare its answers to the known correct ones and make adjustments according to its errors. The neural networks in this chapter follow this model.</li>\n  <li><strong>Unsupervised learning:</strong> This technique is required when you don’t have an example dataset with known answers. Instead, the network works on its own to uncover hidden patterns in the data. An application of this is clustering: a set of elements is divided into groups according to an unknown pattern. I won’t be showing any instances of unsupervised learning, as the strategy is less relevant to the book’s examples.</li>\n  <li><strong>R</strong><strong>einforcement learning:</strong> This strategy is built on observation: a learning agent makes decisions and looks to its environment for the results. It’s rewarded for good decisions and penalized for bad decisions, such that it learns to make better decisions over time. I’ll discuss this strategy in more detail in <a href=\"/neuroevolution#section-neuroevolution\">Chapter 11</a>.</li>\n</ul>\n<p>The ability of a neural network to learn, to make adjustments to its structure over time, is what makes it so useful in the field of <strong>machine learning</strong>. This term can be traced back to the 1959 paper “Some Studies in Machine Learning Using the Game of Checkers,” in which computer scientist Arthur Lee Samuel outlines a “self-learning” program for playing checkers. The concept of an algorithm enabling a computer to learn without explicit programming is the foundation of machine learning.</p>\n<p>Think about what you’ve been doing throughout this book: coding! In traditional programming, a computer program takes inputs and, based on the rules you’ve provided, produces outputs. Machine learning, however, turns this approach upside down. Instead of you writing the rules, the system is given example inputs and outputs, and generates the rules itself! Many algorithms can be used to implement machine learning, and a neural network is just one of them.</p>\n<p>Machine learning is part of the broad, sweeping field of <strong>artificial intelligence (AI)</strong>, although the terms are sometimes used interchangeably. In their thoughtful and friendly primer <em>A People’s Guide to AI</em>, Mimi Onuoha and Diana Nucera (aka Mother Cyborg) define AI as “the theory and development of computer systems able to perform tasks that normally require human intelligence.” Machine learning algorithms are one approach to these tasks, but not all AI systems feature a self-learning component.</p>\n<h3 id=\"machine-learning-libraries\">Machine Learning Libraries</h3>\n<p>Today, leveraging machine learning in creative coding and interactive media isn’t only feasible but increasingly common, thanks to third-party libraries that handle a lot of the neural network implementation details under the hood. While the vast majority of machine learning development and research is done in Python, the world of web development has seen the emergence of powerful JavaScript-based tools. Two libraries of note are TensorFlow.js and ml5.js.</p>\n<p>TensorFlow.js<strong> </strong>is an open source library that lets you define, train, and run neural networks directly in the browser using JavaScript, without the need to install or configure complex environments. It’s part of the TensorFlow ecosystem, which is maintained and developed by Google. TensorFlow.js is a powerful tool, but its low-level operations and highly technical API can be intimidating to beginners. Enter ml5.js, a library built on top of TensorFlow.js and designed specifically for use with p5.js. Its goal is to be beginner friendly and make machine learning approachable for a broad audience of artists, creative coders, and students. I’ll demonstrate how to use ml5.js in <a href=\"#machine-learning-with-ml5js\" class=\"page-reference\">“Machine Learning with ml5.js”</a>.</p>\n<p>A benefit of libraries like TensorFlow.js and ml5.js is that you can use them to run pretrained models. A machine learning <strong>model</strong> is a specific setup of neurons and connections, and a <strong>pretrained</strong> model is one that has already been prepared for a particular task. For example, popular pretrained models are used for classifying images, identifying body poses, recognizing facial landmarks or hand positions, and even analyzing the sentiment expressed in a text. You can use such a model as is or treat it as a starting point for additional learning (commonly referred to as <strong>transfer learning</strong>).</p>\n<p>Before I get to exploring the ml5.js library, however, I’d like to try my hand at building the simplest of all neural networks from scratch, using only p5.js, to illustrate how the concepts of neural networks and machine learning are implemented in code.</p>\n<h2 id=\"the-perceptron\">The Perceptron</h2>\n<div data-type=\"video-link\" data-title=\"Perceptron Part 1\" href=\"https://youtu.be/ntKn5TPHHAk?si=QygKKg9EdyN4mQ_e\"></div>\n<div data-type=\"video-link\" data-title=\"Perceptron Part 2\" href=\"https://youtu.be/DGxIcDjPzac?si=hpKHT0YN3ZTnkVBH\"></div>\n<p>A <strong>perceptron</strong> is the simplest neural network possible: a computational model of a single neuron. Invented in 1957 by Frank Rosenblatt at the Cornell Aeronautical Laboratory, a perceptron consists of one or more inputs, a processor, and a single output, as shown in Figure 10.3.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_4.png\" alt=\"Figure 10.3: A simple perceptron with two inputs and one output\">\n  <figcaption>Figure 10.3: A simple perceptron with two inputs and one output</figcaption>\n</figure>\n<p>A perceptron follows the <strong>feed-forward</strong> model: data passes (feeds) through the network in one direction. The inputs are sent into the neuron, are processed, and result in an output. This means the one-neuron network diagrammed in Figure 10.3 reads from left to right (forward): inputs come in, and output goes out.</p>\n<p>Say I have a perceptron with two inputs, the values 12 and 4. In machine learning, it’s customary to denote each input with an <span data-type=\"equation\">x</span>, so I’ll call these inputs <span data-type=\"equation\">x_0</span> and <span data-type=\"equation\">x_1</span>:</p>\n<table>\n  <thead>\n    <tr>\n      <th style=\"width:100px\">Input</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><span data-type=\"equation\">x_0</span></td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <td><span data-type=\"equation\">x_1</span></td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<h3 id=\"perceptron-steps\">Perceptron Steps</h3>\n<p>To get from these inputs to an output, the perceptron follows a series of steps.</p>\n<h4 id=\"step-1-weight-the-inputs\">Step 1: Weight the Inputs</h4>\n<p>Each input sent into the neuron must first be weighted, meaning it’s multiplied by a value, often a number from –1 to +1. When creating a perceptron, the inputs are typically assigned random weights. I’ll call my weights <span data-type=\"equation\">w_0</span> and <span data-type=\"equation\">w_1</span>:</p>\n<table>\n  <thead>\n    <tr>\n      <th style=\"width:100px\">Weight</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><span data-type=\"equation\">w_0</span></td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <td><span data-type=\"equation\">w_1</span></td>\n      <td>–1</td>\n    </tr>\n  </tbody>\n</table>\n<div class=\"avoid-break\">\n  <p>Each input needs to be multiplied by its corresponding weight:</p>\n  <table>\n    <thead>\n      <tr>\n        <th style=\"width:100px\">Input</th>\n        <th style=\"width:100px\">Weight</th>\n        <th>Input <span data-type=\"equation\">\\boldsymbol{\\times}</span> Weight</th>\n      </tr>\n    </thead>\n    <tbody>\n      <tr>\n        <td>12</td>\n        <td>0.5</td>\n        <td>6</td>\n      </tr>\n      <tr>\n        <td>4</td>\n        <td>–1</td>\n        <td>–4</td>\n      </tr>\n    </tbody>\n  </table>\n</div>\n<h4 id=\"step-2-sum-the-inputs\">Step 2: Sum the Inputs</h4>\n<p>The weighted inputs are then added together:</p>\n<div data-type=\"equation\">6 + -4 = 2</div>\n<h4 id=\"step-3-generate-the-output\">Step 3: Generate the Output</h4>\n<p>The output of a perceptron is produced by passing the sum through an <strong>activation function</strong> that reduces the output to one of two possible values. Think of this binary output as an LED that’s only <em>off</em> or <em>on</em>, or as a neuron in an actual brain that either fires or doesn’t fire. The activation function determines whether the perceptron should “fire.”</p>\n<p>Activation functions can get a little bit hairy. If you start reading about them in an AI textbook, you may soon find yourself reaching in turn for a calculus textbook. However, your new friend the simple perceptron provides an easier option that still demonstrates the concept. I’ll make the activation function the sign of the sum. If the sum is a positive number, the output is 1; if it’s negative, the output is –1:</p>\n<div data-type=\"equation\">\\text{sign}(2) = +1</div>\n<h3 id=\"putting-it-all-together-1\">Putting It All Together</h3>\n<p>Putting the preceding three parts together, here are the steps of the <strong>perceptron algorithm</strong>:</p>\n<ol>\n  <li>For every input, multiply that input by its weight.</li>\n  <li>Sum all the weighted inputs.</li>\n  <li>Compute the output of the perceptron by passing that sum through an activation function (the sign of the sum).</li>\n</ol>\n<p>I can start writing this algorithm in code by using two arrays of values, one for the inputs and one for the weights:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">let inputs = [12, 4];\nlet weights = [0.5, -1];</pre>\n<p>The “for every input” in step 1 implies a loop that multiplies each input by its corresponding weight. To obtain the sum, the results can be added up in that same loop:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// Steps 1 and 2: Add up all the weighted inputs.\nlet sum = 0;\nfor (let i = 0; i &#x3C; inputs.length; i++) {\n  sum += inputs[i] * weights[i];\n}</pre>\n<p>With the sum, I can then compute the output:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// Step 3: Pass the sum through an activation function.\nlet output = activate(sum);\n// The activation function\nfunction activate(sum) {\n  //{!5} Return a 1 if positive, –1 if negative.\n  if (sum > 0) {\n    return 1;\n  } else {\n    return -1;\n  }\n}</pre>\n<p>You might be wondering how I’m handling the value of 0 in the activation function. Is 0 positive or negative? The deep philosophical implications of this question aside, I’m choosing here to arbitrarily return a –1 for 0, but I could easily change the <code>></code> to <code>>=</code> to go the other way. Depending on the application, this decision could be significant, but for demonstration purposes here, I can just pick one.</p>\n<p>Now that I’ve explained the computational process of a perceptron, let’s look at an example of one in action.</p>\n<h3 id=\"simple-pattern-recognition-using-a-perceptron\">Simple Pattern Recognition Using a Perceptron</h3>\n<p>I’ve mentioned that neural networks are commonly used for pattern recognition. The scenarios outlined earlier require more complex networks, but even a simple perceptron can demonstrate a fundamental type of pattern recognition in which data points are classified as belonging to one of two groups. For instance, imagine you have a dataset of plants and want to identify them as either <em>xerophytes</em> (plants that have evolved to survive in an environment with little water and lots of sunlight, like the desert) or <em>hydrophytes</em> (plants that have adapted to living submerged in water, with reduced light). That’s how I’ll use my perceptron in this section.</p>\n<p>One way to approach classifying the plants is to plot their data on a 2D graph and treat the problem as a spatial one. On the x-axis, plot the amount of daily sunlight received by the plant, and on the y-axis, plot the amount of water. Once all the data has been plotted, it’s easy to draw a line across the graph, with all the xerophytes on one side and all the hydrophytes on the other, as in Figure 10.4. (I’m simplifying a little here. Real-world data would probably be messier, making the line harder to draw.) That’s how each plant can be classified. Is it below the line? Then it’s a xerophyte. Is it above the line? Then it’s a hydrophyte.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_5.png\" alt=\"Figure 10.4: A collection of points in 2D space divided by a line, representing plant categories according to their water and sunlight intake \">\n  <figcaption>Figure 10.4: A collection of points in 2D space divided by a line, representing plant categories according to their water and sunlight intake</figcaption>\n</figure>\n<p>In truth, I don’t need a neural network—not even a simple perceptron—to tell me whether a point is above or below a line. I can see the answer for myself with my own eyes, or have my computer figure it out with simple algebra. But just like solving a problem with a known answer—“to be or not to be”—was a convenient first test for the GA in <a href=\"/genetic-algorithms#section-genetic-algorithms\">Chapter 9</a>, training a perceptron to categorize points as being on one side of a line versus the other will be a valuable way to demonstrate the algorithm of the perceptron and verify that it’s working properly.</p>\n<p>To solve this problem, I’ll give my perceptron two inputs: <span data-type=\"equation\">x_0</span> is the x-coordinate of a point, representing a plant’s amount of sunlight, and <span data-type=\"equation\">x_1</span> is the y-coordinate of that point, representing the plant’s amount of water. The perceptron then guesses the plant’s classification according to the sign of the weighted sum of these inputs. If the sum is positive, the perceptron outputs a +1, signifying a hydrophyte (above the line). If the sum is negative, it outputs a –1, signifying a xerophyte (below the line). Figure 10.5 shows this perceptron (note the shorthand of <span data-type=\"equation\">w_0</span> and <span data-type=\"equation\">w_1</span> for the weights).</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_6.png\" alt=\"Figure 10.5: A perceptron with two inputs (x_0 and x_1), a weight for each input (w_0 and w_1), and a processing neuron that generates the output\">\n  <figcaption>Figure 10.5: A perceptron with two inputs (<span data-type=\"equation\">x_0</span> and <span data-type=\"equation\">x_1</span>), a weight for each input (<span data-type=\"equation\">w_0</span> and <span data-type=\"equation\">w_1</span>), and a processing neuron that generates the output</figcaption>\n</figure>\n<p>This scheme has a pretty significant problem, however. What if my data point is (0, 0), and I send<br>this point into the perceptron as inputs <span data-type=\"equation\">x_0 = 0</span> and <span data-type=\"equation\">x_1=0</span>? No matter what the weights are, multiplication by 0 is 0. The weighted inputs are therefore still 0, and their sum will be 0 too. And the sign of 0 is . . . hmmm, there’s that deep philosophical quandary again. Regardless of how I feel about it, the point (0, 0) could certainly be above or below various lines in a 2D world. How is the perceptron supposed to interpret it accurately?</p>\n<p>To avoid this dilemma, the perceptron requires a third input, typically referred to as a <strong>bias</strong> input. This extra input always has the value of 1 and is also weighted. Figure 10.6 shows the perceptron with the addition of the bias.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_7.png\" alt=\"Figure 10.6: Adding a bias input, along with its weight, to the perceptron\">\n  <figcaption>Figure 10.6: Adding a bias input, along with its weight, to the perceptron</figcaption>\n</figure>\n<p>How does this affect point (0, 0)?</p>\n<table>\n  <thead>\n    <tr>\n      <th style=\"width:100px\">Input</th>\n      <th style=\"width:100px\">Weight</th>\n      <th>Result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td><span data-type=\"equation\">w_0</span></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td><span data-type=\"equation\">w_1</span></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td><span data-type=\"equation\">w_\\text{bias}</span></td>\n      <td><span data-type=\"equation\">w_\\text{bias}</span></td>\n    </tr>\n  </tbody>\n</table>\n<p>The output is then the sum of the weighted results: <span data-type=\"equation\">0 + 0 + w_\\text{bias}</span>. Therefore, the bias by itself answers the question of where (0, 0) is in relation to the line. If the bias’s weight is positive, (0, 0) is above the line; if negative, it’s below. The extra input and its weight <em>bias</em> the perceptron’s understanding of the line’s position relative to (0, 0)!</p>\n<h3 id=\"the-perceptron-code\">The Perceptron Code</h3>\n<p>I’m now ready to assemble the code for a <code>Perceptron</code> class. The perceptron needs to track only the input weights, which I can store using an array:</p>\n<div class=\"snip-below\">\n  <pre class=\"codesplit\" data-code-language=\"javascript\">class Perceptron {\n  constructor() {\n    this.weights = [];\n  }</pre>\n</div>\n<p>The constructor can receive an argument indicating the number of inputs (in this case, three: <span data-type=\"equation\">x_0</span>, <span data-type=\"equation\">x_1</span>, and a bias) and size the <code>weights</code> array accordingly, filling it with random values to start:</p>\n<div class=\"snip-above snip-below\">\n  <pre class=\"codesplit\" data-code-language=\"javascript\">\t// The argument <code>n</code> determines the number of inputs (including the bias).\n  constructor(n) {\n    this.weights = [];\n    for (let i = 0; i &#x3C; n; i++) {\n      //{!1} The weights are picked randomly to start.\n      this.weights[i] = random(-1, 1);\n    }\n  }</pre>\n</div>\n<p>A perceptron’s job is to receive inputs and produce an output. These requirements can be packaged together in a <code>feedForward()</code> method. In this example, the perceptron’s inputs are an array (which should be the same length as the array of weights), and the output is a number, +1 or –1, as returned by the activation function based on the sign of the sum:</p>\n<div class=\"snip-above\">\n  <pre class=\"codesplit\" data-code-language=\"javascript\">  feedForward(inputs) {\n    let sum = 0;\n    for (let i = 0; i &#x3C; this.weights.length; i++) {\n      sum += inputs[i] * this.weights[i];\n    }\n    //{!1} The result is the sign of the sum, –1 or +1.\n    // Here the perceptron is making a guess:\n    // Is it on one side of the line or the other?\n    return this.activate(sum);\n  }\n}</pre>\n</div>\n<p>Presumably, I could now create a <code>Perceptron</code> object and ask it to make a guess for any given point, as in Figure 10.7.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_8.png\" alt=\"Figure 10.7: An (x, y) coordinate from the 2D space is the input to the perceptron. \">\n  <figcaption>Figure 10.7: An (<em>x</em>, <em>y</em>) coordinate from the 2D space is the input to the perceptron.</figcaption>\n</figure>\n<p>Here’s the code to generate a guess:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// Create the perceptron.\nlet perceptron = new Perceptron(3);\n// The input is three values: <em>x</em>, <em>y</em>, and the bias.\nlet inputs = [50, -12, 1];\n// The answer!\nlet guess = perceptron.feedForward(inputs);</pre>\n<p>Did the perceptron get it right? Maybe yes, maybe no. At this point, the perceptron has no better than a 50/50 chance of arriving at the correct answer, since each weight starts out as a random value. A neural network isn’t a magic tool that can automatically guess correctly on its own. I need to teach it how to do so!</p>\n<p>To train a neural network to answer correctly, I’ll use the supervised learning method I described earlier in the chapter. Remember, this technique involves giving the network inputs with known answers. This enables the network to check whether it has made a correct guess. If not, the network can learn from its mistake and adjust its weights. The process is as follows:</p>\n<ol>\n  <li>Provide the perceptron with inputs for which there is a known answer.</li>\n  <li>Ask the perceptron to guess an answer.</li>\n  <li>Compute the error. (Did it get the answer right or wrong?)</li>\n</ol>\n<div class=\"avoid-break\">\n  <ol>\n    <li value=\"4\">Adjust all the weights according to the error.</li>\n    <li value=\"5\">Return to step 1 and repeat!</li>\n  </ol>\n</div>\n<p>This process can be packaged into a method on the <code>Perceptron</code> class, but before I can write it, I need to examine steps 3 and 4 in more detail. How do I define the perceptron’s error? And how should I adjust the weights according to this error?</p>\n<p>The perceptron’s error can be defined as the difference between the desired answer and its guess:</p>\n<div data-type=\"equation\">\\text{error} = \\text{desired output} - \\text{guess output}</div>\n<p>Does this formula look familiar? Think back to the formula for a vehicle’s steering force that I worked out in <a href=\"/autonomous-agents#section-autonomous-agents\">Chapter 5</a>:</p>\n<div data-type=\"equation\">\\text{steering} = \\text{desired velocity} - \\text{current velocity}</div>\n<p>This is also a calculation of an error! The current velocity serves as a guess, and the error (the steering force) indicates how to adjust the velocity in the correct direction. Adjusting a vehicle’s velocity to follow a target is similar to adjusting the weights of a neural network toward the correct answer.</p>\n<p>For the perceptron, the output has only two possible values: +1 or –1. Therefore, only three errors are possible. If the perceptron guesses the correct answer, the guess equals the desired output and the error is 0. If the correct answer is –1 and the perceptron guessed +1, then the error is –2. If the correct answer is +1 and the perceptron guessed –1, then the error is +2. Here’s that process summarized in a table:</p>\n<table>\n  <thead>\n    <tr>\n      <th style=\"width:100px\">Desired</th>\n      <th style=\"width:100px\">Guess</th>\n      <th>Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>–1</td>\n      <td>–1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>–1</td>\n      <td>+1</td>\n      <td>–2</td>\n    </tr>\n    <tr>\n      <td>+1</td>\n      <td>–1</td>\n      <td>+2</td>\n    </tr>\n    <tr>\n      <td>+1</td>\n      <td>+1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>The error is the determining factor in how the perceptron’s weights should be adjusted. For any given weight, what I’m looking to calculate is the change in weight, often called <span data-type=\"equation\">\\Delta\\text{weight}</span> (or <em>delta weight</em>, <span data-type=\"equation\">\\Delta</span> being the Greek letter delta):</p>\n<div data-type=\"equation\">\\text{new weight} = \\text{weight} + \\Delta\\text{weight}</div>\n<p>To calculate <span data-type=\"equation\">\\Delta\\text{weight}</span>, I need to multiply the error by the input:</p>\n<div data-type=\"equation\">\\Delta\\text{weight} = \\text{error} \\times \\text{input}</div>\n<p>Therefore, the new weight is calculated as follows:</p>\n<div data-type=\"equation\">\\text{new weight} = \\text{weight} + \\text{error} \\times \\text{input}</div>\n<p>To understand why this works, think again about steering. A steering force is essentially an error in velocity. By applying a steering force as an acceleration (or <span data-type=\"equation\">\\Delta\\text{velocity}</span>), the velocity is adjusted to move in the correct direction. This is what I want to do with the neural network’s weights. I want to adjust them in the right direction, as defined by the error.</p>\n<p>With steering, however, I had an additional variable that controlled the vehicle’s ability to steer: the maximum force. A high maximum force allowed the vehicle to accelerate and turn quickly, while a lower force resulted in a slower velocity adjustment. The neural network will use a similar strategy with a variable called the <strong>learning constant</strong>:</p>\n<div data-type=\"equation\">\\text{new weight} = \\text{weight} + (\\text{error} \\times \\text{input}) \\times \\text{learning constant}</div>\n<p>A high learning constant causes the weight to change more drastically. This may help the perceptron arrive at a solution more quickly, but it also increases the risk of overshooting the optimal weights. A small learning constant will adjust the weights more slowly and require more training time, but will allow the network to make small adjustments that could improve overall accuracy.</p>\n<p>Assuming the addition of a <code>learningConstant</code> property to the <code>Perceptron</code> class, I can now write a training method for the perceptron following the steps I outlined earlier:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">  // Step 1: Provide the inputs and known answer.\n  // These are passed in as arguments to <code>train()</code>.\n  train(inputs, desired) {\n    // Step 2: Guess according to those inputs.\n    let guess = this.feedforward(inputs);\n    // Step 3: Compute the error (the difference between <code>desired</code> and <code>guess</code>).\n    let error = desired - guess;\n    //{!3} Step 4: Adjust all the weights according to the error and learning constant.\n    for (let i = 0; i &#x3C; this.weights.length; i++) {\n      this.weights[i] = this.weights[i] + error * inputs[i] * this.learningConstant;\n    }\n  }</pre>\n<p>Here’s the <code>Perceptron</code> class as a whole:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">class Perceptron {\n  constructor(totalInputs) {\n    //{!2} The perceptron stores its weights and learning constants.\n    this.weights = [];\n    this.learningConstant = 0.01;\n    //{!3} The weights start off random.\n    for (let i = 0; i &#x3C; totalInputs; i++) {\n      this.weights[i] = random(-1, 1);\n    }\n  }\n\n  //{!7} Return an output based on inputs.\n  feedforward(inputs) {\n    let sum = 0;\n    for (let i = 0; i &#x3C; this.weights.length; i++) {\n      sum += inputs[i] * this.weights[i];\n    }\n    return this.activate(sum);\n  }\n\n  // The output is a +1 or –1.\n  activate(sum) {\n    if (sum > 0) {\n      return 1;\n    } else {\n      return -1;\n    }\n  }\n\n  //{!4} Train the network against known data.\n  train(inputs, desired) {\n    let guess = this.feedforward(inputs);\n    let error = desired - guess;\n    for (let i = 0; i &#x3C; this.weights.length; i++) {\n      //{!3.continue}\n      this.weights[i] = this.weights[i] + error * inputs[i] * this.learningConstant;\n    }\n  }\n}</pre>\n<p>To train the perceptron, I need a set of inputs with known answers. However, I don’t happen to have a real-world dataset (or time to research and collect one) for the xerophytes and hydrophytes scenario. In truth, though, the purpose of this demonstration isn’t to show you how to classify plants. It’s about how a perceptron can learn whether points are above or below a line on a graph, and so any set of points will do. In other words, I can just make up the data.</p>\n<p>What I’m describing is an example of <strong>synthetic data</strong>, artificially generated data that’s often used in machine learning to create controlled scenarios for training and testing. In this case, my synthetic data will consist of a set of random input points, each with a known answer indicating whether the point is above or below a line. To define the line and generate the data, I’ll use simple algebra. This approach allows me to clearly demonstrate the training process and show how the perceptron learns.</p>\n<p>The question therefore becomes, how do I pick a point and know whether it’s above or below a line (without a neural network, that is)? A line can be described as a collection of points, where each point’s y-coordinate is a function of its x-coordinate:</p>\n<div data-type=\"equation\">y = f(x)</div>\n<p>For a straight line (specifically, a linear function), the relationship can be written like this:</p>\n<div data-type=\"equation\">y = mx + b</div>\n<p>Here <em>m</em> is the slope of the line, and <em>b</em> is the value of <em>y</em> when <em>x</em> is 0 (the y-intercept). Here’s a specific example, with the corresponding graph in Figure 10.8.</p>\n<div data-type=\"equation\">y = \\frac{1}2x - 1</div>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_9.png\" alt=\"Figure 10.8: A graph of y = frac{1}2x - 1\">\n  <figcaption>Figure 10.8: A graph of <span data-type=\"equation\">y = \\frac{1}2x - 1</span></figcaption>\n</figure>\n<p>I’ll arbitrarily choose that as the equation for my line, and write a function accordingly:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// A function to calculate <code>y</code> based on <code>x</code> along a line\nfunction f(x) {\n  return 0.5 * x - 1;\n}</pre>\n<p>Now there’s the matter of the p5.js canvas defaulting to (0, 0) in the top-left corner with the y-axis pointing down. For this discussion, I’ll assume I’ve built the following into the code to reorient the canvas to match a more traditional Cartesian space.</p>\n<div class=\"avoid-break\">\n  <pre class=\"codesplit\" data-code-language=\"javascript\">// Move the origin <code>(0, 0)</code> to the center.\ntranslate(width / 2, height / 2);\n// Flip the y-axis orientation (positive points up!).\nscale(1, -1);</pre>\n</div>\n<p>I can now pick a random point in the 2D space:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">let x = random(-100, 100);\nlet y = random(-100, 100);</pre>\n<p>How do I know if this point is above or below the line? The line function <em>f</em>(<em>x</em>) returns the <em>y</em> value on the line for that x-position. I’ll call that <span data-type=\"equation\">y_\\text{line}</span>:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// The <code>y</code> position on the line\nlet yline = f(x);</pre>\n<p>If the <em>y</em> value I’m examining is above the line, it will be greater than <span data-type=\"equation\">y_\\text{line}</span>, as in Figure 10.9.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_10.png\" alt=\"Figure 10.9: If y_\text{line} is less than y, the point is above the line.\">\n  <figcaption>Figure 10.9: If <span data-type=\"equation\">y_\\text{line}</span> is less than <em>y</em>, the point is above the line.</figcaption>\n</figure>\n<p>Here’s the code for that logic:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// Start with a value of –1.\nlet desired = -1;\nif (y > yline) {\n  //{!1} The answer becomes +1 if <code>y</code> is above the line.\n  desired = 1;\n}</pre>\n<p>I can then make an input array to go with the <code>desired</code> output:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// Don’t forget to include the bias!\nlet trainingInputs = [x, y, 1];</pre>\n<p>Assuming that I have a <code>perceptron</code> variable, I can train it by providing the inputs along with the desired answer:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">perceptron.train(trainingInputs, desired);</pre>\n<p>If I train the perceptron on a new random point (and its answer) for each cycle through <code>draw()</code>, it will gradually get better at classifying the points as above or below the line.</p>\n<div data-type=\"example\">\n  <h3 id=\"example-101-the-perceptron\">Example 10.1: The Perceptron</h3>\n  <figure>\n    <div data-type=\"embed\" data-p5-editor=\"https://editor.p5js.org/natureofcode/sketches/sMozIaMCW\" data-example-path=\"examples/10_nn/10_1_perceptron_with_normalization\"><img src=\"/content/examples/10_nn/10_1_perceptron_with_normalization/screenshot.png\"></div>\n    <figcaption></figcaption>\n  </figure>\n</div>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// The perceptron\nlet perceptron;\n//{!1} An array for training data\nlet training = [];\n// A counter to track training data points one by one\nlet count = 0;\n\n//{!3} The formula for a line\nfunction f(x) {\n  return 0.5 * x + 1;\n}\n\nfunction setup() {\n  createCanvas(640, 240);\n  // The perceptron has three inputs (including bias) and a learning rate of 0.0001.\n  perceptron = new Perceptron(3, 0.0001);\n  //{!1} Make 2,000 training data points.\n  for (let i = 0; i &#x3C; 2000; i++) {\n    let x = random(-width / 2, width / 2);\n    let y = random(-height / 2, height / 2);\n    training[i] = [x, y, 1];\n  }\n}\n\nfunction draw() {\n  background(255);\n  // Reorient the canvas to match a traditional Cartesian plane.\n  translate(width / 2, height / 2);\n  scale(1, -1);\n  // Draw the line.\n  stroke(0);\n  strokeWeight(2);\n  line(-width / 2, f(-width / 2), width / 2, f(width / 2));\n  // Get the current <code>(x, y)</code> of the training data.\n  let x = training[count][0];\n  let y = training[count][1];\n  // What is the desired output?\n  let desired = -1;\n  if (y > f(x)) {\n    desired = 1;\n  }\n  // Train the perceptron.\n  perceptron.train(training[count], desired);\n  // For animation, train one point at a time.\n  count = (count + 1) % training.length;\n  // Draw all the points and color according to the output of the perceptron.\n  for (let dataPoint of training) {\n    let guess = perceptron.feedforward(dataPoint);\n    if (guess > 0) {\n      fill(127);\n    } else {\n      fill(255);\n    }\n    strokeWeight(1);\n    stroke(0);\n    circle(dataPoint[0], dataPoint[1], 8);\n  }\n}</pre>\n<p>In Example 10.1, the training data is visualized alongside the target solution line. Each point represents a piece of training data, and its color is determined by the perceptron’s current classification—gray for +1 or white for –1. I use a small learning constant (0.0001) to slow down how the system refines its classifications over time.</p>\n<p>An intriguing aspect of this example lies in the relationship between the perceptron’s weights and the characteristics of the line dividing the points—specifically, the line’s slope and y-intercept (the <em>m</em> and <em>b</em> in <em>y</em> = <em>mx</em> + <em>b</em>). The weights in this context aren’t just arbitrary or “magic” values; they bear a direct relationship to the geometry of the dataset. In this case, I’m using just 2D data, but for many machine learning applications, the data exists in much higher-dimensional spaces. The weights of a neural network help navigate these spaces, defining <em>hyperplanes</em> or decision boundaries that segment and classify the data.</p>\n<div data-type=\"exercise\">\n  <h3 id=\"exercise-101\">Exercise 10.1</h3>\n  <p>Modify the code from Example 10.1 to also draw the perceptron’s current decision boundary during the training process—its best guess for where the line should be. Hint: Use the perceptron’s current weights to calculate the line’s equation.</p>\n</div>\n<p>While this perceptron example offers a conceptual foundation, real-world datasets often feature more diverse and dynamic ranges of input values. For the simplified scenario here, the range of values for <em>x</em> is larger than that for <em>y</em> because of the canvas size of 640<span data-type=\"equation\">\\times</span>240. Despite this, the example still works—after all, the sign activation function doesn’t rely on specific input ranges, and it’s such a straightforward binary classification task.</p>\n<p>However, real-world data often has much greater complexity in terms of input ranges. To this end, <strong>data normalization</strong> is a critical step in machine learning. Normalizing data involves mapping the training data to ensure that all inputs (and outputs) conform to a uniform range—typically 0 to 1, or perhaps –1 to 1. This process can improve training efficiency and prevent individual inputs from dominating the learning process. In the next section, using the ml5.js library, I’ll build data normalization into the process.</p>\n<div data-type=\"exercise\">\n  <h3 id=\"exercise-102\">Exercise 10.2</h3>\n  <p>Instead of using supervised learning, can you train the neural network to find the right weights by using a GA?</p>\n</div>\n<div data-type=\"exercise\">\n  <h3 id=\"exercise-103\">Exercise 10.3</h3>\n  <p>Incorporate data normalization into the example. Does this improve the learning efficiency?</p>\n</div>\n<h2 id=\"putting-the-network-in-neural-network\">Putting the “Network” in Neural Network</h2>\n<div data-type=\"video-link\" data-title=\"Multilayer Perceptron Part 1\" href=\"https://youtu.be/u5GAVdLQyIg?si=SK5RH74Pb_9soFpb\"></div>\n<div data-type=\"video-link\" data-title=\"Multilayer Perceptron Part 2\" href=\"https://youtu.be/IlmNhFxre0w?si=bjcUGsSZBIM7rXUO\"></div>\n<p>A perceptron can have multiple inputs, but it’s still just a single, lonely neuron. Unfortunately, that limits the range of problems it can solve. The true power of neural networks comes from the <em>network</em> part. Link multiple neurons together and you’re able to solve problems of much greater complexity.</p>\n<p>If you read an AI textbook, it will say that a perceptron can solve only <strong>linearly separable</strong> problems. If a dataset is linearly separable, you can graph it and classify it into two groups simply by drawing a straight line (see Figure 10.10, left). Classifying plants as xerophytes or hydrophytes is a linearly separable problem.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_11.png\" alt=\"Figure 10.10: Data points that are linearly separable (left) and data points that are nonlinearly separable, as a curve is required to separate the points (right)\">\n  <figcaption>Figure 10.10: Data points that are linearly separable (left) and data points that are nonlinearly separable, as a curve is required to separate the points (right)</figcaption>\n</figure>\n<p>Now imagine you’re classifying plants according to soil acidity (x-axis) and temperature (y-axis). Some plants might thrive in acidic soils but only within a narrow temperature range, while other plants prefer less acidic soils but tolerate a broader range of temperatures. A more complex relationship exists between the two variables, so a straight line can’t be drawn to separate the two categories of plants, <em>acidophilic</em> and <em>alkaliphilic</em> (see Figure 10.10, right). A lone perceptron can’t handle this type of <strong>nonlinearly separable</strong> problem. (Caveat here: I’m making up these scenarios. If you happen to be a botanist, please let me know if I’m anywhere close to reality.)</p>\n<p>One of the simplest examples of a nonlinearly separable problem is XOR (exclusive or). This is a logical operator, similar to the more familiar AND and OR. For <em>A</em> AND <em>B </em>to be true, both <em>A</em> and <em>B</em> must be true. With OR, either <em>A</em> or <em>B</em> (or both) can be true. These are both linearly separable problems. The truth tables in Figure 10.11 show their solution space. Each true or false value in the table shows the output for a particular combination of true or false inputs. See how you can draw a straight line to separate the true outputs from the false ones?</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_12.png\" alt=\"Figure 10.11: Truth tables for the AND and OR logical operators. The true and false outputs can be separated by a line.\">\n  <figcaption>Figure 10.11: Truth tables for the AND and OR logical operators. The true and false outputs can be separated by a line.</figcaption>\n</figure>\n<div class=\"avoid-break\">\n  <p>The XOR operator is the equivalent of (OR) AND (NOT AND). In other words, <em>A</em> XOR <em>B </em>evaluates to true only if one of the inputs is true. If both inputs are false or both are true, the output is false. To illustrate, let’s say you’re having pizza for dinner. You love pineapple on pizza, and you love mushrooms on pizza, but put them together—yech! And plain pizza, that’s no good either!</p>\n</div>\n<p>The XOR truth table in Figure 10.12 isn’t linearly separable. Try to draw a straight line to separate the true outputs from the false ones—you can’t!</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_13.png\" alt=\"Figure 10.12: The truth tables for whether you want to eat the pizza (left) and XOR (right). Note how the true and false outputs can’t be separated by a single line.\">\n  <figcaption>Figure 10.12: The truth tables for whether you want to eat the pizza (left) and XOR (right). Note how the true and false outputs can’t be separated by a single line.</figcaption>\n</figure>\n<p>The fact that a perceptron can’t even solve something as simple as XOR may seem extremely limiting. But what if I made a network out of two perceptrons? If one perceptron can solve the linearly separable OR and one perceptron can solve the linearly separate NOT AND, then two perceptrons combined can solve the nonlinearly separable XOR.</p>\n<p>When you combine multiple perceptrons, you get a <strong>multilayered perceptron</strong>, a network of many neurons (see Figure 10.13). Some are input neurons and receive the initial inputs, some are part of what’s called a <strong>hidden layer</strong> (as they’re connected to neither the inputs nor the outputs of the network directly), and then there are the output neurons, from which the results are read.</p>\n<p>Up until now, I’ve been visualizing a singular perceptron with one circle representing a neuron processing its input signals. Now, as I move on to larger networks, it’s more typical to represent<br>all the elements (inputs, neurons, outputs) as circles, with arrows that indicate the flow of data. In Figure 10.13, you can see the inputs and bias flowing into the hidden layer, which then flows to the output.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_14.png\" alt=\"Figure 10.13: A multilayered perceptron has the same inputs and output as the simple perceptron, but now it includes a hidden layer of neurons.\">\n  <figcaption>Figure 10.13: A multilayered perceptron has the same inputs and output as the simple perceptron, but now it includes a hidden layer of neurons.</figcaption>\n</figure>\n<p>Training a simple perceptron is pretty straightforward: you feed the data through and evaluate how to change the input weights according to the error. With a multilayered perceptron, however, the training process becomes more complex. The overall output of the network is still generated in essentially the same manner as before: the inputs multiplied by the weights are summed and fed forward through the various layers of the network. And you still use the network’s guess to calculate the error (desired result – guess). But now so many connections exist between layers of the network, each with its own weight. How do you know how much each neuron or connection contributed to the overall error of the network, and how it should be adjusted?</p>\n<p>The solution to optimizing the weights of a multilayered network is <strong>backpropagation</strong>. This process takes the error and feeds it backward through the network so it can adjust the weights of all the connections in proportion to how much they’ve contributed to the total error. The details of backpropagation are beyond the scope of this book. The algorithm uses a variety of activation functions (one classic example is the sigmoid function) as well as some calculus. If you’re interested<br>in continuing down this road and learning more about how backpropagation works, you can find<br>my <a href=\"https://thecodingtrain.com/neural-network\">“Toy Neural Network” project at the Coding Train website with accompanying video tutorials</a>. They go through all the steps of solving XOR using a multilayered feed-forward network with backpropagation. For this chapter, however, I’d instead like to get some help and phone a friend.</p>\n<h2 id=\"machine-learning-with-ml5js\">Machine Learning with ml5.js</h2>\n<p>That friend is ml5.js. This machine learning library can manage the details of complex processes like backpropagation so you and I don’t have to worry about them. As I mentioned earlier in the chapter, ml5.js aims to provide a friendly entry point for those who are new to machine learning and neural networks, while still harnessing the power of Google’s TensorFlow.js behind the scenes.</p>\n<p>To use ml5.js in a sketch, you must import it via a <code>&#x3C;script></code> element in your <em>index.html</em> file, much as you did with Matter.js and Toxiclibs.js in <a href=\"/physics-libraries#section-physics-libraries\">Chapter 6</a>:</p>\n<pre class=\"codesplit\" data-code-language=\"html\">&#x3C;script src=\"https://unpkg.com/ml5@1/dist/ml5.min.js\">&#x3C;/script></pre>\n<p>My goal for the rest of this chapter is to introduce ml5.js by developing a system that can recognize mouse gestures. This will prepare you for <a href=\"/neuroevolution#section-neuroevolution\">Chapter 11</a>, where I’ll add a neural network “brain” to an autonomous steering agent and tie machine learning back into the story of the book. First, however, I’d like to talk more generally through the steps of training a multilayered neural network model using supervised learning. Outlining these steps will highlight important decisions you’ll have to make before developing a learning model, introduce the syntax of the ml5.js library, and provide you with the context you’ll need before training your own machine learning models.</p>\n<h3 id=\"the-machine-learning-life-cycle\">The Machine Learning Life Cycle</h3>\n<p>The life cycle of a machine learning model is typically broken into seven steps:</p>\n<ol>\n  <li><strong>Collect the data.</strong> Data forms the foundation of any machine learning task. This stage might involve running experiments, manually inputting values, sourcing public data, or a myriad of other methods (like generating synthetic data).</li>\n  <li><strong>Prepare the data.</strong> Raw data often isn’t in a format suitable for machine learning algorithms. It might also have duplicate or missing values, or contain outliers that skew the data. Such inconsistencies may need to be manually adjusted. Additionally, as I mentioned earlier, neural networks work best with normalized data, which has values scaled to fit within a standard range. Another key part of preparing data is separating it into distinct sets: training, validation, and testing. The training data is used to teach the model (step 4), while the validation and testing data (the distinction is subtle—more on this later) are set aside and reserved for evaluating the model’s performance (step 5).</li>\n  <li><strong>Choose a model.</strong> Design the architecture of the neural network. Different models are more suitable for certain types of data and outputs.</li>\n</ol>\n<div class=\"avoid-break\">\n  <ol>\n    <li value=\"4\"><strong>Train the model.</strong> Feed the training portion of the data through the model and allow the model to adjust the weights of the neural network based on its errors. This process is known as <strong>optimization</strong>: the model tunes the weights so they result in the fewest number of errors.</li>\n  </ol>\n</div>\n<ol>\n  <li value=\"5\"><strong>Evaluate the model.</strong> Remember the testing data that was set aside in step 2? Since that data wasn’t used in training, it provides a means to evaluate how well the model performs on new, unseen data.</li>\n  <li value=\"6\"><strong>Tune the parameters.</strong> The training process is influenced by a set of parameters (often called <strong>hyperparameters</strong>) such as the learning rate, which dictates how much the model should adjust its weights based on errors in prediction. I called this the <code>learningConstant</code> in the perceptron example. By fine-tuning these parameters and revisiting steps 4 (training), 3 (model selection), and even 2 (data preparation), you can often improve the model’s performance.</li>\n  <li value=\"7\"><strong>Deploy the model. </strong>Once the model is trained and its performance is evaluated satisfactorily, it’s time to use the model out in the real world with new data!</li>\n</ol>\n<p>These steps are the cornerstone of supervised machine learning. However, even though 7 is a truly excellent number, I think I missed one more critical step. I’ll call it step 0.</p>\n<ol>\n  <li value=\"0\"><strong>Identify the problem.</strong> This initial step defines the problem that needs solving. What is the objective? What are you trying to accomplish or predict with your machine learning model?</li>\n</ol>\n<p>This zeroth step informs all the other steps in the process. After all, how are you supposed to collect your data and choose a model without knowing what you’re even trying to do? Are you predicting a number? A category? A sequence? Is it a binary choice, or are there many options? These sorts of questions often boil down to choosing between two types of tasks that the majority of machine learning applications fall into: classification and regression.</p>\n<h3 id=\"classification-and-regression\">Classification and Regression</h3>\n<p><strong>Classification</strong> is a type of machine learning problem that involves predicting a <strong>label</strong> (also called a <strong>category</strong> or <strong>class</strong>) for a piece of data. If this sounds familiar, that’s because it is: the simple perceptron in Example 10.1 was trained to classify points as above or below a line. To give another example, an image classifier might try to guess if a photo is of a cat or a dog and assign the corresponding label (see Figure 10.14).</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_15.png\" alt=\"Figure 10.14: Labeling images as cats or dogs\">\n  <figcaption>Figure 10.14: Labeling images as cats or dogs</figcaption>\n</figure>\n<p>Classification doesn’t happen by magic. The model must first be shown many examples of dogs and cats with the correct labels in order to properly configure the weights of all the connections. This is the training part of supervised learning.</p>\n<p>The classic “Hello, world!” demonstration of machine learning and supervised learning is a classification problem of the MNIST dataset. Short for <em>Modified National Institute of Standards and Technology</em>, <strong>MNIST</strong> is a dataset that was collected and processed by Yann LeCun (Courant Institute, NYU), Corinna Cortes (Google Labs), and Christopher J.C. Burges (Microsoft Research). Widely used for training and testing in the field of machine learning, this dataset consists of 70,000 handwritten digits from 0 to 9; each is a 28<span data-type=\"equation\">\\times</span>28-pixel grayscale image (see Figure 10.15 for examples). Each image is labeled with its corresponding digit.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_16.png\" alt=\"Figure 10.15: A selection of handwritten digits 0–9 from the MNIST dataset (courtesy of Suvanjanprasai)\">\n  <figcaption>Figure 10.15: A selection of handwritten digits 0–9 from the MNIST dataset (courtesy of Suvanjanprasai)</figcaption>\n</figure>\n<p>MNIST is a canonical example of a training dataset for image classification: the model has a discrete number of categories to choose from (10 to be exact—no more, no less). After the model is trained on the 70,000 labeled images, the goal is for it to classify new images and assign the appropriate label, a digit from 0 to 9.</p>\n<p><strong>Regression</strong>, on the other hand, is a machine learning task for which the prediction is a continuous value, typically a floating-point number. A regression problem can involve multiple outputs, but thinking about just one is often simpler to start. For example, consider a machine learning model that predicts the daily electricity usage of a house based on input factors like the number of occupants, the size of the house, and the temperature outside (see Figure 10.16).</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_17.png\" alt=\"Figure 10.16: Factors like weather and the size and occupancy of a home can influence its daily electricity usage.\">\n  <figcaption>Figure 10.16: Factors like weather and the size and occupancy of a home can influence its daily electricity usage.</figcaption>\n</figure>\n<p>Rather than picking from a discrete set of output options, the goal of the neural network is now to guess a number—any number. Will the house use 30.5 kilowatt-hours of electricity that day? Or 48.7 kWh? Or 100.2 kWh? The output prediction could be any value from a continuous range.</p>\n<h3 id=\"network-design\">Network Design</h3>\n<p>Knowing what problem you’re trying to solve (step 0) also has a significant bearing on the design of the neural network—in particular, on its input and output layers. I’ll demonstrate with another classic “Hello, world!” classification example from the field of data science and machine learning: the iris dataset. This dataset, which can be found in the Machine Learning Repository at the University of California, Irvine, originated from the work of American botanist Edgar Anderson.</p>\n<p>Anderson collected flower data over many years across multiple regions of the United States and Canada. For more on the origins of this famous dataset, see <a href=\"https://academic.oup.com/jrssig/article/18/6/26/7038520\">“The Iris Data Set: In Search of the Source of <em>Virginica</em>” by Antony Unwin and Kim Kleinman</a>. After carefully analyzing the data, Anderson built a table to classify iris flowers into three distinct species: <em>Iris setosa</em>, <em>Iris versicolor</em>, and <em>Iris virginica </em>(see Figure 10.17).</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_18.png\" alt=\"Figure 10.17: Three distinct species of iris flowers\">\n  <figcaption>Figure 10.17: Three distinct species of iris flowers</figcaption>\n</figure>\n<p>Anderson included four numeric attributes for each flower: sepal length, sepal width, petal length, and petal width, all measured in centimeters. (He also recorded color information, but that data appears to have been lost.) Each record is then paired with the appropriate iris categorization:</p>\n<table>\n  <thead>\n    <tr>\n      <th>Sepal Length</th>\n      <th>Sepal Width</th>\n      <th>Petal Length</th>\n      <th>Petal Width</th>\n      <th>Classification</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td><em>Iris setosa</em></td>\n    </tr>\n    <tr>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td><em>Iris setosa</em></td>\n    </tr>\n    <tr>\n      <td>7.0</td>\n      <td>3.2</td>\n      <td>4.7</td>\n      <td>1.4</td>\n      <td><em>Iris versicolor</em></td>\n    </tr>\n    <tr>\n      <td>6.4</td>\n      <td>3.2</td>\n      <td>4.5</td>\n      <td>1.5</td>\n      <td><em>Iris versicolor</em></td>\n    </tr>\n    <tr>\n      <td>6.3</td>\n      <td>3.3</td>\n      <td>6.0</td>\n      <td>2.5</td>\n      <td><em>Iris virginica</em></td>\n    </tr>\n    <tr>\n      <td>5.8</td>\n      <td>2.7</td>\n      <td>5.1</td>\n      <td>1.9</td>\n      <td><em>Iris virginica</em></td>\n    </tr>\n  </tbody>\n</table>\n<p>In this dataset, the first four columns (sepal length, sepal width, petal length, petal width) serve as inputs to the neural network. The output is the classification provided in the fifth column. Figure 10.18 depicts a possible architecture for a neural network that can be trained on this data.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_19.png\" alt=\"Figure 10.18: A possible network architecture for iris classification\">\n  <figcaption>Figure 10.18: A possible network architecture for iris classification</figcaption>\n</figure>\n<p>On the left are the four inputs to the network, corresponding to the first four columns of the data table. On the right are three possible outputs, each representing one of the iris species labels. In between is the hidden layer, which, as mentioned earlier, adds complexity to the network’s architecture, necessary for handling nonlinearly separable data. Each node in the hidden layer is connected to every node that comes before and after it. This is commonly called a <strong>fully connected</strong> or <strong>dense </strong>layer.</p>\n<p>You might also notice the absence of explicit bias nodes in this diagram. While biases play an important role in the output of each neuron, they’re often left out of visual representations to keep the diagrams clean and focused on the primary data flow. (The ml5.js library will ultimately manage the biases for me internally.)</p>\n<p>The neural network’s goal is to “activate” the correct output for the input data, just as the perceptron would output a +1 or –1 for its single binary classification. In this case, the output values are like signals that help the network decide which iris species label to assign. The highest computed value activates to signify the network’s best guess about the classification.</p>\n<p>The key takeaway here is that a classification network should have as many inputs as there are values for each item in the dataset, and as many outputs as there are categories. As for the hidden layer, the design is much less set in stone. The hidden layer in Figure 10.18 has five nodes, but this number is entirely arbitrary. Neural network architectures can vary greatly, and the number of hidden nodes is often determined through trial and error or other educated guessing methods (called <em>heuristics</em>). In the context of this book, I’ll be relying on ml5.js to automatically configure the architecture based on the input and output data.</p>\n<p>What about the inputs and outputs in a regression scenario, like the household electricity consumption example I mentioned earlier? I’ll go ahead and make up a dataset for this scenario,<br>with values representing the occupants and size of the house, the day’s temperature, and the corresponding electricity usage. This is much like a synthetic dataset, given that it’s not data collected for a real-world scenario—but whereas synthetic data is generated automatically, here I’m manually inputting numbers from my own imagination:</p>\n<table>\n  <tbody>\n    <tr>\n      <td><strong>Occupants</strong></td>\n      <td><strong>Size (m²)</strong></td>\n      <td><strong>Temperature Outside (°C)</strong></td>\n      <td><strong>Electricity Usage (kWh)</strong></td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>150</td>\n      <td>24</td>\n      <td>25.3</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>100</td>\n      <td>25.5</td>\n      <td>16.2</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>70</td>\n      <td>26.5</td>\n      <td>12.1</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>120</td>\n      <td>23</td>\n      <td>22.1</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>90</td>\n      <td>21.5</td>\n      <td>15.2</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>180</td>\n      <td>20</td>\n      <td>24.4</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>60</td>\n      <td>18.5</td>\n      <td>11.7</td>\n    </tr>\n  </tbody>\n</table>\n<p>The neural network for this problem should have three input nodes corresponding to the first three columns (occupants, size, temperature). Meanwhile, it should have one output node representing the fourth column, the network’s guess about the electricity usage. And I’ll arbitrarily say the network’s hidden layer should have four nodes rather than five. Figure 10.19 shows this network architecture.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_20.png\" alt=\"Figure 10.19: A possible network architecture for three inputs and one regression output\">\n  <figcaption>Figure 10.19: A possible network architecture for three inputs and one regression output</figcaption>\n</figure>\n<p>Unlike the iris classification network, which is choosing from three labels and therefore has three outputs, this network is trying to predict just one number, so it has only one output. I’ll note, however, that a single output isn’t a requirement of regression. A machine learning model can also perform a regression that predicts multiple continuous values, in which case the model would have multiple outputs.</p>\n<h3 id=\"ml5js-syntax\">ml5.js Syntax</h3>\n<p>The ml5.js library is a collection of machine learning models that can be accessed using the syntax <code>ml5.<em>functionName</em>()</code>. For example, to use a pretrained model that detects hand positions, you can use <code>ml5.handPose()</code>. For classifying images, you can use <code>ml5.imageClassifier()</code>. While I encourage you to explore all that ml5.js has to offer (I’ll reference some of these pretrained models in upcoming exercise ideas), for this chapter I’ll focus on only one function in ml5.js, <code>ml5.neuralNetwork()</code>, which creates an empty neural network for you to train.</p>\n<p>To use this function, you must first create a JavaScript object that will configure the model being created. Here’s where some of the big-picture factors I just discussed—is this a classification or a regression task? How many inputs and outputs?—come into play. I’ll begin by specifying the task I want the model to perform (<code>\"regression\"</code> or <code>\"classification\"</code>):</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">let options = { task: \"classification\" };\nlet classifier = ml5.neuralNetwork(options);</pre>\n<p>This, however, gives ml5.js little to go on in terms of designing the network architecture. Adding the inputs and outputs will complete the rest of the puzzle. The iris flower classification has four inputs and three possible output labels. This can be configured as part of the <code>options</code> object with a single integer for the number of inputs and an array of strings listing the output labels:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">let options = {\n  inputs: 4,\n  outputs: [\"iris-setosa\", \"iris-virginica\", \"iris-versicolor\"],\n  task: \"classification\",\n};\nlet digitClassifier = ml5.neuralNetwork(options);</pre>\n<p>The electricity regression scenario had three input values (occupants, size, temperature) and one output value (usage in kWh). With regression, there are no string output labels, so only an integer indicating the number of outputs is required:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">let options = {\n  inputs: 3,\n  outputs: 1,\n  task: \"regression\",\n};\nlet energyPredictor = ml5.neuralNetwork(options);</pre>\n<p>You can set many other properties of the model through the <code>options</code> object. For example, you could specify the number of hidden layers between the inputs and outputs (there are typically several), the number of neurons in each layer, which activation functions to use, and more. In most cases, however, you can leave out these extra settings and let ml5.js make its best guess on how to design the model based on the task and data at hand.</p>\n<h2 id=\"building-a-gesture-classifier\">Building a Gesture Classifier</h2>\n<p>I’ll now walk through the steps of the machine learning life cycle with an example problem well<br>suited for p5.js, building all the code for each step along the way using ml5.js. I’ll begin at step 0 by articulating the problem. Imagine for a moment that you’re working on an interactive application that responds to gestures. Maybe the gestures are ultimately meant to be recorded via body tracking, but you want to start with something much simpler—a single stroke of the mouse (see Figure 10.20).</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_21.png\" alt=\"Figure 10.20: A single mouse gesture as a vector between a start and end point\">\n  <figcaption>Figure 10.20:<em> </em>A single mouse gesture as a vector between a start and end point</figcaption>\n</figure>\n<p>Each gesture could be recorded as a vector extending from the start to the end point of a mouse movement. The x- and y-components of the vector will be the model’s inputs. The model’s task could be to predict one of four possible labels for the gesture: <em>up</em>, <em>down</em>, <em>left</em>, or <em>right</em>. With a discrete set of possible outputs, this sounds like a classification problem. The four labels will be the model’s outputs.</p>\n<p>Much like some of the GA demonstrations in <a href=\"/genetic-algorithms#section-genetic-algorithms\">Chapter 9</a>—and like the simple perceptron example earlier in this chapter—the problem I’m selecting here has a known solution and could be solved more easily and efficiently without a neural network. The direction of a vector can be classified with the <code>heading()</code> function and a series of <code>if</code> statements! However, by using this seemingly trivial scenario, I hope to explain the process of training a machine learning model in an understandable and friendly way. Additionally, this example will make it easy to check that the code is working as expected. When I’m done, I’ll provide some ideas about how to expand the classifier to a scenario that couldn’t use simple <code>if</code> statements.</p>\n<h3 id=\"collecting-and-preparing-the-data\">Collecting and Preparing the Data</h3>\n<p>With the problem established, I can turn to steps 1 and 2: collecting and preparing the data. In the real world, these steps can be tedious, especially when the raw data you collect is messy and needs a lot of initial processing. You can think of this like having to organize, wash, and chop all your ingredients before you can start cooking a meal from scratch.</p>\n<p>For simplicity, I’d instead like to take the approach of ordering a machine learning “meal kit,” with the ingredients (data) already portioned and prepared. This way, I’ll get straight to the cooking itself, the process of training the model. After all, this is really just an appetizer for what will be the ultimate meal in <a href=\"/neuroevolution#section-neuroevolution\">Chapter 11</a>, when I apply neural networks to steering agents.</p>\n<p>With that in mind, I’ll handcode some example data and manually keep it normalized within a range of –1 and +1. I’ll organize the data into an array of objects, pairing the x- and y-components of a vector with a string label. I’m picking values that I feel clearly point in a specific direction and assigning the appropriate label—two examples per label:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">let data = [\n  { x: 0.99, y: 0.02, label: \"right\" },\n  { x: 0.76, y: -0.1, label: \"right\" },\n  { x: -1.0, y: 0.12, label: \"left\" },\n  { x: -0.9, y: -0.1, label: \"left\" },\n  { x: 0.02, y: 0.98, label: \"down\" },\n  { x: -0.2, y: 0.75, label: \"down\" },\n  { x: 0.01, y: -0.9, label: \"up\" },\n  { x: -0.1, y: -0.8, label: \"up\" },\n];</pre>\n<p>Figure 10.21 shows the same data expressed as arrows.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_22.png\" alt=\"Figure 10.21: The input data visualized as vectors (arrows)\">\n  <figcaption>Figure 10.21: The input data visualized as vectors (arrows)</figcaption>\n</figure>\n<p>In a more realistic scenario, I’d probably have a much larger dataset that would be loaded in from a separate file, instead of written directly into the code. For example, JavaScript Object Notation (JSON) and comma-separated values (CSV) are two popular formats for storing and loading data. JSON stores data in key-value pairs and follows the same exact format as JavaScript object literals. CSV is a file format that stores tabular data (like a spreadsheet). You could use numerous other data formats, depending on your needs and the programming environment you’re working with.</p>\n<p>In the real world, the values in that larger dataset would actually come from somewhere. Maybe I would collect the data by asking users to perform specific gestures and recording their inputs, or by writing an algorithm to automatically generate larger amounts of synthetic data that represent the idealized versions of the gestures I want the model to recognize. In either case, the key would be to collect a diverse set of examples that adequately represent the variations in how the gestures might be performed. For now, however, let’s see how it goes with just a few servings of data.</p>\n<div data-type=\"exercise\">\n  <h3 id=\"exercise-104\">Exercise 10.4</h3>\n  <p>Create a p5.js sketch that collects gesture data from users and saves it to a JSON file. You can use <code>mousePressed()</code> and <code>mouseReleased()</code> to mark the start and end of each gesture, and <code>saveJSON()</code> to download the data into a file.</p>\n</div>\n<h3 id=\"choosing-a-model\"><strong>Choosing a Model</strong></h3>\n<p>I’ve now come to step 3 of the machine learning life cycle, selecting a model. This is where I’m going to start letting ml5.js do the heavy lifting for me. To create the model with ml5.js, all I need to do is specify the task, the inputs, and the outputs:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">let options = {\n  task: \"classification\",\n  inputs: 2,\n  outputs: [\"up\", \"down\", \"left\", \"right\"],\n  debug: true\n};\nlet classifier = ml5.neuralNetwork(options);</pre>\n<p>That’s it! I’m done! Thanks to ml5.js, I can bypass a host of complexities such as the number of layers and neurons per layer to have, the kinds of activation functions to use, and how to set up the algorithms for training the network. The library will make these decisions for me.</p>\n<p>Of course, the default ml5.js model architecture may not be perfect for all cases. I encourage you to read the ml5.js documentation for additional details on how to customize the model. I’ll also point out that ml5.js is able to infer the inputs and outputs from the data, so those properties aren’t entirely necessary to include here in the <code>options</code> object. However, for the sake of clarity (and since I’ll need to specify them for later examples), I’m including them here.</p>\n<p>The <code>debug</code> property, when set to <code>true</code>, turns on a visual interface for the training process. It’s a helpful tool for spotting potential issues during training and for getting a better understanding of what’s happening behind the scenes. You’ll see what this interface looks like later in the chapter.</p>\n<h3 id=\"training-the-model\">Training the Model</h3>\n<p>Now that I have the data in a <code>data</code> variable and a neural network initialized in the <code>classifier</code> variable, I’m ready to train the model. That process starts with adding the data to the model. And for that, it turns out I’m not quite done with preparing the data.</p>\n<p>Right now, my data is neatly organized in an array of objects, each containing the x- and y-components of a vector and a corresponding string label. This is a typical format for training data, but it isn’t directly consumable by ml5.js. (Sure, I could have initially organized the data into a format that ml5.js recognizes, but I’m including this extra step because it will likely be necessary when you’re using a dataset that has been collected or sourced elsewhere.) To add the data to the model, I need to separate the inputs from the outputs so that the model understands which are which.</p>\n<p>The ml5.js library offers a fair amount of flexibility in the kinds of formats it will accept, but I’ll choose to use arrays—one for the <code>inputs</code> and one for the <code>outputs</code>. I can use a loop to reorganize each data item and add it to the model:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">for (let item of data) {\n  // An array of two numbers for the inputs\n  let inputs = [item.x, item.y];\n  // A single string label for the output\n  let outputs = [item.label];\n  //{!1} Add the training data to the classifier.\n  classifier.addData(inputs, outputs);\n}</pre>\n<p>What I’ve done here is set the <strong>shape</strong> of the data. In machine learning, this term describes the data’s dimensions and structure. It indicates how the data is organized in terms of rows, columns, and potentially even deeper, into additional dimensions. Understanding the shape of your data is crucial because it determines the way the model should be structured.</p>\n<p>Here, the input data’s shape is a 1D array containing two numbers (representing <em>x</em> and <em>y</em>). The output data, similarly, is a 1D array containing just a single string label. Every piece of data going in and out of the network will follow this pattern. While this is a small and simple example, it nicely mirrors many real-world scenarios in which the inputs are numerically represented in an array, and the outputs are string labels.</p>\n<p>After passing the data into the <code>classifier</code>, ml5.js provides a helper function to normalize it. As I’ve mentioned, normalizing data (adjusting the scale to a standard range) is a critical step in the machine learning process:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// Normalize the data.\nclassifier.normalizeData();</pre>\n<p>In this case, the handcoded data was limited to a range of –1 to +1 from the get-go, so calling <code>normalizeData()</code> here is likely redundant. Still, this function call is important to demonstrate. Normalizing your data ahead of time as part of the preprocessing step will absolutely work, but the auto-normalization feature of ml5.js is a big help!</p>\n<p>Now for the heart of the machine learning process: actually training the model. Here’s the code:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// The <code>train()</code> method initiates the training process.\nclassifier.train(finishedTraining);\n// A callback function for when the training is complete\nfunction finishedTraining() {\n  console.log(\"Training complete!\");\n}</pre>\n<p>Yes, that’s it! After all, the hard work has already been completed. The data was collected, prepared, and fed into the model. All that remains is to call the <code>train()</code> method, sit back, and let ml5.js do its thing.</p>\n<p>In truth, it isn’t <em>quite</em> that simple. If I were to run the code as written and then test the model, the results would probably be inadequate. Here’s where another key term in machine learning comes into play: <strong>epochs</strong>. The <code>train()</code> method tells the neural network to start the learning process. But how long should it train for? You can think of an epoch as one round of practice, one cycle of using the entire training dataset to update the weights of the neural network. Generally speaking, the more epochs you go through, the better the network will perform, but at a certain point you’ll have diminishing returns. The number of epochs can be set by passing in an <code>options</code> object into <code>train()</code>.</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">//{!1} Set the number of epochs for training.\nlet options = { epochs: 25 };\nclassifier.train(options, finishedTraining);</pre>\n<p>The number of epochs is an example of a hyperparameter, a global setting for the training process. You can set others through the <code>options</code> object (the learning rate, for example), but I’m going to stick with the defaults. You can read more about customization options in the ml5.js documentation.</p>\n<p>The second argument to <code>train()</code> is optional, but it’s good to include one. It specifies a callback function that runs when the training process is complete—in this case, <code>finishedTraining()</code>. (See the “Callbacks” box for more on callback functions.) This is useful for knowing when you can proceed to the next steps in your code. Another optional callback, which I usually name <code>whileTraining()</code>, is triggered after each epoch. However, for my purposes, knowing when the training is done is plenty!</p>\n<div data-type=\"note\">\n  <h3 id=\"callbacks\">Callbacks</h3>\n  <p>A <strong>callback function</strong> in JavaScript is a function you don’t actually call yourself. Instead, you provide it as an argument to another function, intending for it to be <em>called back</em> automatically at a later time (typically associated with an event, like a mouse click). You’ve seen this before when working with Matter.js in <a href=\"/physics-libraries#section-physics-libraries\">Chapter 6</a>, where you specified a function to call whenever a collision was detected.</p>\n  <p>Callbacks are needed for <strong>asynchronous</strong> operations, when you want your code to continue along with animating or doing other things while waiting for another task (like training a machine learning model) to finish. A classic example of this in p5.js is loading data into a sketch with <code>loadJSON()</code>.</p>\n  <p>JavaScript also provides a more recent approach for handling asynchronous operations known as <strong>promises</strong>. With promises, you can use keywords like <code>async</code> and <code>await</code> to make your asynchronous code look more like traditional synchronous code. While ml5.js also supports this style, I’ll stick to using callbacks to stay aligned with p5.js style.</p>\n</div>\n<h3 id=\"evaluating-the-model\">Evaluating the Model</h3>\n<p>If <code>debug</code> is set to <code>true</code> in the initial call to <code>ml5.neuralNetwork()</code>, a visual interface should appear after <code>train()</code> is called, covering most of the p5.js page and canvas (see Figure 10.22). This interface, called the <em>Visor</em>, represents the evaluation step.</p>\n<figure>\n  <img src=\"/content/images/10_nn/10_nn_23.png\" alt=\"Figure 10.22: The Visor, with a graph of the loss function and model details\">\n  <figcaption>Figure 10.22: The Visor, with a graph of the loss function and model details</figcaption>\n</figure>\n<p>The Visor comes from TensorFlow.js (which underlies ml5.js) and includes a graph that provides real-time feedback on the progress of the training. This graph plots the loss of the model on the y-axis against the number of epochs along the x-axis. <strong>Loss</strong> is a measure of how far off the model’s predictions are from the correct outputs provided by the training data. It quantifies the model’s total error. When training begins, it’s common for the loss to be high because the model has yet to learn anything. Ideally, as the model trains through more epochs, it should get better at its predictions, and the loss should decrease. If the graph goes down as the epochs increase, this is a good sign!</p>\n<p>Running the training for the 200 epochs depicted in Figure 10.21 might strike you as a bit excessive. In a real-world scenario with more extensive data, I would probably use fewer epochs, like the 25 I specified in the original code snippet. However, because the dataset here is so tiny, the higher number of epochs helps the model get enough practice with the data. Remember, this is a toy example, aiming to make the concepts clear rather than to produce a sophisticated machine learning model.</p>\n<p>Below the graph, the Visor shows a Model Summary table with details on the lower-level TensorFlow.js model architecture created behind the scenes. The summary includes layer names, neuron counts per layer (in the Output Shape column), and a parameters count, which is the total number of weights, one for each connection between two neurons. In this case, dense_Dense1 is the hidden layer with 16 neurons (a number chosen by ml5.js), and dense_Dense2 is the output layer with 4 neurons, one for each classification category. (TensorFlow.js doesn’t think of the inputs as a distinct layer; rather, they’re merely the starting point of the data flow.) The <em>batch</em> in the Output Shape column doesn’t refer to a specific number but indicates that the model can process a variable amount of training data (a batch) for any single cycle of model training.</p>\n<p>Before moving on from the evaluation stage, I have a loose end to tie up. When I first outlined the steps of the machine learning life cycle, I mentioned that preparing the data typically involves splitting the dataset into three parts to help with the evaluation process:</p>\n<ul>\n  <li><strong>Training:</strong> The primary dataset used to train the model</li>\n  <li><strong>Validation:</strong> A subset of the data used to check the model during training, typically at the end of each epoch</li>\n  <li><strong>Testing:</strong> Additional untouched data never considered during the training process, for determining the model’s final performance after the training is completed</li>\n</ul>\n<p>You may have noticed that I never did this. For simplicity, I’ve instead used the entire dataset for training. After all, my dataset has only eight records; it’s much too small to divide three sets! With a large dataset, this three-way split would be more appropriate.</p>\n<p>Using such a small dataset risks the model <strong>overfitting</strong> the data, however: the model becomes so tuned to the specific peculiarities of the training data that it’s much less effective when working with new, unseen data. The main reason to use a validation set is to monitor the model during the training process. As training progresses, if the model’s accuracy improves on the training data but deteriorates on the validation data, it’s a strong indicator that overfitting might be occurring. (The testing set is reserved strictly for the final evaluation, one more chance after training is complete to gauge the model’s performance.)</p>\n<p>For more realistic scenarios, ml5.js provides a way to split up the data, as well as automatic features for employing validation data. If you’re inclined to go further, <a href=\"https://ml5js.org/\">you can explore the full set of neural network examples on the ml5.js website</a>.</p>\n<h3 id=\"tuning-the-parameters\">Tuning the Parameters</h3>\n<p>After the evaluation step, there’s typically an iterative process of adjusting hyperparameters and going through training again to achieve the best performance from the model. While ml5.js offers capabilities for parameter tuning (which you can learn about in the library’s reference), it isn’t really geared toward making low-level, fine-grained adjustments to a model. Using TensorFlow.js directly might be your best bet if you want to explore this step in more detail, since it offers a broader suite of tools and allows for lower-level control over the training process.</p>\n<p>In this case, tuning the parameters isn’t strictly necessary. The graph in the Visor shows a loss all the way down at 0.1, which is plenty accurate for my purposes. I’m happy to move on.</p>\n<h3 id=\"deploying-the-model\">Deploying the Model</h3>\n<p>It’s finally time to deploy the model and see the payoff of all that hard work. This typically involves integrating the model into a separate application to make predictions or decisions based on new, previously unseen data. For this, ml5.js offers the convenience of a <code>save()</code> function to download the trained model to a file from one sketch and a <code>load()</code> function to load it for use in a completely different sketch. This saves you from having to retrain the model from scratch every single time you need it.</p>\n<p>While a model would typically be deployed to a different sketch from the one where it was trained, I’m going to deploy the model in the same sketch for the sake of simplicity. In fact, once the training process is complete, the resulting model is, in essence, already deployed in the current sketch. It’s saved in the <code>classifier</code> variable and can be used to make predictions by passing the model new data through the <code>classify()</code> method. The shape of the data sent to <code>classify()</code> should match that of the input data used in training—in this case, two floating-point numbers, representing the x- and y-components of a direction vector:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// Manually create a vector.\nlet direction = createVector(1, 0);\n// Convert the x- and y-components into an input array.\nlet inputs = [direction.x, direction.y];\n// Ask the model to classify the inputs.\nclassifier.classify(inputs, gotResults);</pre>\n<p>The second argument to <code>classify()</code> is another callback function for accessing the results:</p>\n<pre class=\"codesplit\" data-code-language=\"javascript\">function gotResults(results) {\n  console.log(results);\n}</pre>\n<p>The model’s prediction arrives in the argument to the callback, which I’m calling <code>results</code> in the code. Inside, you’ll find an array of the possible labels, sorted by <strong>confidence</strong>, a probability value that the model assigns to each label. These probabilities represent how sure the model is of that particular prediction. They range from 0 to 1, with values closer to 1 indicating higher confidence and values near 0 suggesting lower confidence:</p>\n<pre class=\"codesplit\" data-code-language=\"json\">[\n  {\n    \"label\": \"right\",\n    \"confidence\": 0.9669702649116516\n  },\n  {\n    \"label\": \"up\",\n    \"confidence\": 0.01878807507455349\n  },\n  {\n    \"label\": \"down\",\n    \"confidence\": 0.013948931358754635\n  },\n  {\n    \"label\": \"left\",\n    \"confidence\": 0.00029277068097144365\n  }\n]</pre>\n<p>In this example output, the model is highly confident (approximately 96.7 percent) that the correct label is <code>\"right\"</code>, while it has minimal confidence (0.03 percent) in the <code>\"left\"</code> label. The confidence values are normalized and add up to 100 percent.</p>\n<p>All that remains now is to fill out the sketch with code so the model can receive live input from the mouse. The first step is to signal the completion of the training process so the user knows the model is ready. I’ll include a global <code>status</code> variable to track the training process and ultimately display the predicted label on the canvas. The variable is initialized to <code>\"training\"</code> but updated to <code>\"ready\"</code> through the <code>finishedTraining()</code> callback.</p>\n<div class=\"avoid-break\">\n  <pre class=\"codesplit\" data-code-language=\"javascript\">// When the sketch starts, it will show a status of <code>training</code>.\nlet status = \"training\";\n\nfunction draw() {\n  background(255);\n  textAlign(CENTER, CENTER);\n  textSize(64);\n  text(status, width / 2, height / 2);\n}\n\n// This is the callback for when training is complete, and the message changes to <code>ready</code>.\nfunction finishedTraining() {\n  status = \"ready\";\n}</pre>\n</div>\n<p>Finally, I’ll use p5.js’s mouse functions to build a vector while the mouse is being dragged and call <code>classifier.classify()</code> on that vector when the mouse is clicked.</p>\n<div data-type=\"example\">\n  <h3 id=\"example-102-gesture-classifier\">Example 10.2: Gesture Classifier</h3>\n  <figure>\n    <div data-type=\"embed\" data-p5-editor=\"https://editor.p5js.org/natureofcode/sketches/SbfSv_GhM\" data-example-path=\"examples/10_nn/10_2_gesture_classifier\"><img src=\"/content/examples/10_nn/10_2_gesture_classifier/screenshot.png\"></div>\n    <figcaption></figcaption>\n  </figure>\n</div>\n<pre class=\"codesplit\" data-code-language=\"javascript\">// Store the start of a gesture when the mouse is pressed.\nfunction mousePressed() {\n  start = createVector(mouseX, mouseY);\n}\n\n// Update the end of a gesture as the mouse is dragged.\nfunction mouseDragged() {\n  end = createVector(mouseX, mouseY);\n}\n\n// The gesture is complete when the mouse is released.\nfunction mouseReleased() {\n  // Calculate and normalize a direction vector.\n  let dir = p5.Vector.sub(end, start);\n  dir.normalize();\n  // Convert to an input array and classify.\n  let inputs = [dir.x, dir.y];\n  classifier.classify(inputs, gotResults);\n}\n\n// Store the resulting label in the <code>status</code> variable for showing in the canvas.\nfunction gotResults(error, results) {\n  status = results[0].label;\n}</pre>\n<p>Since the <code>results</code> array is sorted by confidence, if I just want to use a single label as the prediction, I can access the first element of the array with <code>results[0].label</code>, as in the <code>gotResults()</code> function in Example 10.2. This label is passed to the <code>status</code> variable to be displayed on the canvas.</p>\n<div data-type=\"exercise\">\n  <h3 id=\"exercise-105\">Exercise 10.5</h3>\n  <p>Divide Example 10.2 into three sketches: one for collecting data, one for training, and one for deployment. Use the <code>ml5.neuralNetwork</code> functions <code>save()</code> and <code>load()</code> for saving and loading the model to and from a file, respectively.</p>\n</div>\n<div data-type=\"exercise\">\n  <h3 id=\"exercise-106\">Exercise 10.6</h3>\n  <p>Expand the gesture-recognition model to classify a sequence of vectors, capturing more accurately the path of a longer mouse movement. Remember, your input data must have a consistent shape, so you’ll have to decide how many vectors to use to represent a gesture and store no more and no less for each data point. While this approach can work, other machine learning models (such as recurrent neural networks) are specifically designed to handle sequential data and might offer more flexibility and potential accuracy.</p>\n</div>\n<div data-type=\"exercise\">\n  <h3 id=\"exercise-107\">Exercise 10.7</h3>\n  <p>One of the pretrained models in ml5.js is called <em>Handpose</em>. The input of the model is an image, and the prediction is a list of 21 key points—x- and y-positions, also known as <em>landmarks</em>—that describe a hand.</p>\n  <figure>\n    <img src=\"/content/images/10_nn/10_nn_24.png\" alt>\n    <figcaption></figcaption>\n  </figure>\n  <p>Can you use the outputs of the <code>ml5.handpose()</code> model as the inputs to an <code>ml5.neuralNetwork()</code> and classify various hand gestures (like a thumbs-up or thumbs-down)? For hints, you can watch my <a href=\"https://thecodingtrain.com/pose-classifier\">video tutorial that walks you through this process for body poses in the machine learning track on the Coding Train website</a>.</p>\n</div>\n<div data-type=\"project\">\n  <h3 id=\"the-ecosystem-project-11\">The Ecosystem Project</h3>\n  <p>Incorporate machine learning into your ecosystem to enhance the behavior of creatures. How could classification or regression be applied?</p>\n  <ul>\n    <li>Can you classify the creatures of your ecosystem into multiple categories? What if you use an initial population as a training dataset, and as new creatures are born, the system classifies them according to their features? What are the inputs and outputs for your system?</li>\n    <li>Can you use a regression to predict the life span of a creature based on its properties? Think about how size and speed affected the life span of the bloops from <a href=\"/genetic-algorithms#section-genetic-algorithms\">Chapter 9</a>. Could you analyze how well the regression model’s predictions align with the actual outcomes?</li>\n  </ul>\n  <figure>\n    <img src=\"/content/images/10_nn/10_nn_25.png\" alt>\n    <figcaption></figcaption>\n  </figure>\n</div>\n<p></p>\n</section>",
  "codeBlocks": [
    {
      "id": "code-0",
      "language": "javascript",
      "code": "let inputs = [12, 4];\nlet weights = [0.5, -1];",
      "lineNumbers": false
    },
    {
      "id": "code-1",
      "language": "javascript",
      "code": "// Steps 1 and 2: Add up all the weighted inputs.\nlet sum = 0;\nfor (let i = 0; i < inputs.length; i++) {\n  sum += inputs[i] * weights[i];\n}",
      "lineNumbers": false
    },
    {
      "id": "code-2",
      "language": "javascript",
      "code": "// Step 3: Pass the sum through an activation function.\nlet output = activate(sum);\n// The activation function\nfunction activate(sum) {\n  //{!5} Return a 1 if positive, –1 if negative.\n  if (sum > 0) {\n    return 1;\n  } else {\n    return -1;\n  }\n}",
      "lineNumbers": true
    },
    {
      "id": "code-3",
      "language": "javascript",
      "code": "class Perceptron {\n  constructor() {\n    this.weights = [];\n  }",
      "lineNumbers": false
    },
    {
      "id": "code-4",
      "language": "javascript",
      "code": "// The argument <code>n</code> determines the number of inputs (including the bias).\n  constructor(n) {\n    this.weights = [];\n    for (let i = 0; i < n; i++) {\n      //{!1} The weights are picked randomly to start.\n      this.weights[i] = random(-1, 1);\n    }\n  }",
      "lineNumbers": true
    },
    {
      "id": "code-5",
      "language": "javascript",
      "code": "feedForward(inputs) {\n    let sum = 0;\n    for (let i = 0; i < this.weights.length; i++) {\n      sum += inputs[i] * this.weights[i];\n    }\n    //{!1} The result is the sign of the sum, –1 or +1.\n    // Here the perceptron is making a guess:\n    // Is it on one side of the line or the other?\n    return this.activate(sum);\n  }\n}",
      "lineNumbers": true
    },
    {
      "id": "code-6",
      "language": "javascript",
      "code": "// Create the perceptron.\nlet perceptron = new Perceptron(3);\n// The input is three values: <em>x</em>, <em>y</em>, and the bias.\nlet inputs = [50, -12, 1];\n// The answer!\nlet guess = perceptron.feedForward(inputs);",
      "lineNumbers": true
    },
    {
      "id": "code-7",
      "language": "javascript",
      "code": "// Step 1: Provide the inputs and known answer.\n  // These are passed in as arguments to <code>train()</code>.\n  train(inputs, desired) {\n    // Step 2: Guess according to those inputs.\n    let guess = this.feedforward(inputs);\n    // Step 3: Compute the error (the difference between <code>desired</code> and <code>guess</code>).\n    let error = desired - guess;\n    //{!3} Step 4: Adjust all the weights according to the error and learning constant.\n    for (let i = 0; i < this.weights.length; i++) {\n      this.weights[i] = this.weights[i] + error * inputs[i] * this.learningConstant;\n    }\n  }",
      "lineNumbers": true
    },
    {
      "id": "code-8",
      "language": "javascript",
      "code": "class Perceptron {\n  constructor(totalInputs) {\n    //{!2} The perceptron stores its weights and learning constants.\n    this.weights = [];\n    this.learningConstant = 0.01;\n    //{!3} The weights start off random.\n    for (let i = 0; i < totalInputs; i++) {\n      this.weights[i] = random(-1, 1);\n    }\n  }\n\n  //{!7} Return an output based on inputs.\n  feedforward(inputs) {\n    let sum = 0;\n    for (let i = 0; i < this.weights.length; i++) {\n      sum += inputs[i] * this.weights[i];\n    }\n    return this.activate(sum);\n  }\n\n  // The output is a +1 or –1.\n  activate(sum) {\n    if (sum > 0) {\n      return 1;\n    } else {\n      return -1;\n    }\n  }\n\n  //{!4} Train the network against known data.\n  train(inputs, desired) {\n    let guess = this.feedforward(inputs);\n    let error = desired - guess;\n    for (let i = 0; i < this.weights.length; i++) {\n      //{!3.continue}\n      this.weights[i] = this.weights[i] + error * inputs[i] * this.learningConstant;\n    }\n  }\n}",
      "lineNumbers": true
    },
    {
      "id": "code-9",
      "language": "javascript",
      "code": "// A function to calculate <code>y</code> based on <code>x</code> along a line\nfunction f(x) {\n  return 0.5 * x - 1;\n}",
      "lineNumbers": false
    },
    {
      "id": "code-10",
      "language": "javascript",
      "code": "// Move the origin <code>(0, 0)</code> to the center.\ntranslate(width / 2, height / 2);\n// Flip the y-axis orientation (positive points up!).\nscale(1, -1);",
      "lineNumbers": false
    },
    {
      "id": "code-11",
      "language": "javascript",
      "code": "let x = random(-100, 100);\nlet y = random(-100, 100);",
      "lineNumbers": false
    },
    {
      "id": "code-12",
      "language": "javascript",
      "code": "// The <code>y</code> position on the line\nlet yline = f(x);",
      "lineNumbers": false
    },
    {
      "id": "code-13",
      "language": "javascript",
      "code": "// Start with a value of –1.\nlet desired = -1;\nif (y > yline) {\n  //{!1} The answer becomes +1 if <code>y</code> is above the line.\n  desired = 1;\n}",
      "lineNumbers": true
    },
    {
      "id": "code-14",
      "language": "javascript",
      "code": "// Don’t forget to include the bias!\nlet trainingInputs = [x, y, 1];",
      "lineNumbers": false
    },
    {
      "id": "code-15",
      "language": "javascript",
      "code": "perceptron.train(trainingInputs, desired);",
      "lineNumbers": false
    },
    {
      "id": "code-16",
      "language": "javascript",
      "code": "// The perceptron\nlet perceptron;\n//{!1} An array for training data\nlet training = [];\n// A counter to track training data points one by one\nlet count = 0;\n\n//{!3} The formula for a line\nfunction f(x) {\n  return 0.5 * x + 1;\n}\n\nfunction setup() {\n  createCanvas(640, 240);\n  // The perceptron has three inputs (including bias) and a learning rate of 0.0001.\n  perceptron = new Perceptron(3, 0.0001);\n  //{!1} Make 2,000 training data points.\n  for (let i = 0; i < 2000; i++) {\n    let x = random(-width / 2, width / 2);\n    let y = random(-height / 2, height / 2);\n    training[i] = [x, y, 1];\n  }\n}\n\nfunction draw() {\n  background(255);\n  // Reorient the canvas to match a traditional Cartesian plane.\n  translate(width / 2, height / 2);\n  scale(1, -1);\n  // Draw the line.\n  stroke(0);\n  strokeWeight(2);\n  line(-width / 2, f(-width / 2), width / 2, f(width / 2));\n  // Get the current <code>(x, y)</code> of the training data.\n  let x = training[count][0];\n  let y = training[count][1];\n  // What is the desired output?\n  let desired = -1;\n  if (y > f(x)) {\n    desired = 1;\n  }\n  // Train the perceptron.\n  perceptron.train(training[count], desired);\n  // For animation, train one point at a time.\n  count = (count + 1) % training.length;\n  // Draw all the points and color according to the output of the perceptron.\n  for (let dataPoint of training) {\n    let guess = perceptron.feedforward(dataPoint);\n    if (guess > 0) {\n      fill(127);\n    } else {\n      fill(255);\n    }\n    strokeWeight(1);\n    stroke(0);\n    circle(dataPoint[0], dataPoint[1], 8);\n  }\n}",
      "lineNumbers": true
    },
    {
      "id": "code-17",
      "language": "html",
      "code": "<script src=\"https://unpkg.com/ml5@1/dist/ml5.min.js\"></script>",
      "lineNumbers": false
    },
    {
      "id": "code-18",
      "language": "javascript",
      "code": "let options = { task: \"classification\" };\nlet classifier = ml5.neuralNetwork(options);",
      "lineNumbers": false
    },
    {
      "id": "code-19",
      "language": "javascript",
      "code": "let options = {\n  inputs: 4,\n  outputs: [\"iris-setosa\", \"iris-virginica\", \"iris-versicolor\"],\n  task: \"classification\",\n};\nlet digitClassifier = ml5.neuralNetwork(options);",
      "lineNumbers": true
    },
    {
      "id": "code-20",
      "language": "javascript",
      "code": "let options = {\n  inputs: 3,\n  outputs: 1,\n  task: \"regression\",\n};\nlet energyPredictor = ml5.neuralNetwork(options);",
      "lineNumbers": true
    },
    {
      "id": "code-21",
      "language": "javascript",
      "code": "let data = [\n  { x: 0.99, y: 0.02, label: \"right\" },\n  { x: 0.76, y: -0.1, label: \"right\" },\n  { x: -1.0, y: 0.12, label: \"left\" },\n  { x: -0.9, y: -0.1, label: \"left\" },\n  { x: 0.02, y: 0.98, label: \"down\" },\n  { x: -0.2, y: 0.75, label: \"down\" },\n  { x: 0.01, y: -0.9, label: \"up\" },\n  { x: -0.1, y: -0.8, label: \"up\" },\n];",
      "lineNumbers": true
    },
    {
      "id": "code-22",
      "language": "javascript",
      "code": "let options = {\n  task: \"classification\",\n  inputs: 2,\n  outputs: [\"up\", \"down\", \"left\", \"right\"],\n  debug: true\n};\nlet classifier = ml5.neuralNetwork(options);",
      "lineNumbers": true
    },
    {
      "id": "code-23",
      "language": "javascript",
      "code": "for (let item of data) {\n  // An array of two numbers for the inputs\n  let inputs = [item.x, item.y];\n  // A single string label for the output\n  let outputs = [item.label];\n  //{!1} Add the training data to the classifier.\n  classifier.addData(inputs, outputs);\n}",
      "lineNumbers": true
    },
    {
      "id": "code-24",
      "language": "javascript",
      "code": "// Normalize the data.\nclassifier.normalizeData();",
      "lineNumbers": false
    },
    {
      "id": "code-25",
      "language": "javascript",
      "code": "// The <code>train()</code> method initiates the training process.\nclassifier.train(finishedTraining);\n// A callback function for when the training is complete\nfunction finishedTraining() {\n  console.log(\"Training complete!\");\n}",
      "lineNumbers": true
    },
    {
      "id": "code-26",
      "language": "javascript",
      "code": "//{!1} Set the number of epochs for training.\nlet options = { epochs: 25 };\nclassifier.train(options, finishedTraining);",
      "lineNumbers": false
    },
    {
      "id": "code-27",
      "language": "javascript",
      "code": "// Manually create a vector.\nlet direction = createVector(1, 0);\n// Convert the x- and y-components into an input array.\nlet inputs = [direction.x, direction.y];\n// Ask the model to classify the inputs.\nclassifier.classify(inputs, gotResults);",
      "lineNumbers": true
    },
    {
      "id": "code-28",
      "language": "javascript",
      "code": "function gotResults(results) {\n  console.log(results);\n}",
      "lineNumbers": false
    },
    {
      "id": "code-29",
      "language": "json",
      "code": "[\n  {\n    \"label\": \"right\",\n    \"confidence\": 0.9669702649116516\n  },\n  {\n    \"label\": \"up\",\n    \"confidence\": 0.01878807507455349\n  },\n  {\n    \"label\": \"down\",\n    \"confidence\": 0.013948931358754635\n  },\n  {\n    \"label\": \"left\",\n    \"confidence\": 0.00029277068097144365\n  }\n]",
      "lineNumbers": true
    },
    {
      "id": "code-30",
      "language": "javascript",
      "code": "// When the sketch starts, it will show a status of <code>training</code>.\nlet status = \"training\";\n\nfunction draw() {\n  background(255);\n  textAlign(CENTER, CENTER);\n  textSize(64);\n  text(status, width / 2, height / 2);\n}\n\n// This is the callback for when training is complete, and the message changes to <code>ready</code>.\nfunction finishedTraining() {\n  status = \"ready\";\n}",
      "lineNumbers": true
    },
    {
      "id": "code-31",
      "language": "javascript",
      "code": "// Store the start of a gesture when the mouse is pressed.\nfunction mousePressed() {\n  start = createVector(mouseX, mouseY);\n}\n\n// Update the end of a gesture as the mouse is dragged.\nfunction mouseDragged() {\n  end = createVector(mouseX, mouseY);\n}\n\n// The gesture is complete when the mouse is released.\nfunction mouseReleased() {\n  // Calculate and normalize a direction vector.\n  let dir = p5.Vector.sub(end, start);\n  dir.normalize();\n  // Convert to an input array and classify.\n  let inputs = [dir.x, dir.y];\n  classifier.classify(inputs, gotResults);\n}\n\n// Store the resulting label in the <code>status</code> variable for showing in the canvas.\nfunction gotResults(error, results) {\n  status = results[0].label;\n}",
      "lineNumbers": true
    }
  ],
  "images": [
    "images/10_nn/10_nn_1.jpg",
    "images/10_nn/10_nn_2.png",
    "images/10_nn/10_nn_3.png",
    "images/10_nn/10_nn_4.png",
    "images/10_nn/10_nn_5.png",
    "images/10_nn/10_nn_6.png",
    "images/10_nn/10_nn_7.png",
    "images/10_nn/10_nn_8.png",
    "images/10_nn/10_nn_9.png",
    "images/10_nn/10_nn_10.png",
    "examples/10_nn/10_1_perceptron_with_normalization/screenshot.png",
    "images/10_nn/10_nn_11.png",
    "images/10_nn/10_nn_12.png",
    "images/10_nn/10_nn_13.png",
    "images/10_nn/10_nn_14.png",
    "images/10_nn/10_nn_15.png",
    "images/10_nn/10_nn_16.png",
    "images/10_nn/10_nn_17.png",
    "images/10_nn/10_nn_18.png",
    "images/10_nn/10_nn_19.png",
    "images/10_nn/10_nn_20.png",
    "images/10_nn/10_nn_21.png",
    "images/10_nn/10_nn_22.png",
    "images/10_nn/10_nn_23.png",
    "examples/10_nn/10_2_gesture_classifier/screenshot.png",
    "images/10_nn/10_nn_24.png",
    "images/10_nn/10_nn_25.png"
  ]
}